{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b7553a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Step 1: Data Preparation for Probing Fine tuned model\n",
      "Loading data from local file: en_ewt-ud-train.conllu...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing sentences: 100%|██████████| 12544/12544 [00:00<00:00, 58635.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset prepared for probing.\n",
      "Number of sentences in dataset: 12544\n",
      "Total sentences in probing subset: 2000\n",
      "Sample data: {'tokens': ['A', 'key', 'question', 'is', 'how', 'they', 'acquired', 'the', 'anthrax', 'strain', 'first', 'isolated', 'by', 'the', 'Texas', 'Veterinary', 'Medical', 'Diagnostic', 'Lab', 'in', '1980', '.'], 'char_labels': [0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 2, 1, 2, 0, 0, 0, 0], 'syll_labels': [0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 2, 0, 0, 0, 2, 2, 2, 0, 0, 0, 0]}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from datasets import Dataset\n",
    "from tqdm.auto import tqdm\n",
    "import os\n",
    "import pickle\n",
    "import pyphen\n",
    "import conllu \n",
    "from transformers import (\n",
    "    DistilBertTokenizerFast, \n",
    "    DistilBertForSequenceClassification, \n",
    "    DistilBertModel\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy.stats import spearmanr\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "print(\" Step 1: Data Preparation for Probing Fine tuned model\")\n",
    "\n",
    "file_path = \"en_ewt-ud-train.conllu\"\n",
    "\n",
    "try:\n",
    "    print(f\"Loading data from local file: {file_path}...\")\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        parsed_data = conllu.parse(f.read())\n",
    "    \n",
    "    words = []\n",
    "    char_labels_data = []\n",
    "    syll_labels_data = []\n",
    "\n",
    "    char_label_map = {0: 'short', 1: 'medium', 2: 'long'}\n",
    "    syll_label_map = {0: 'short', 1: 'medium', 2: 'long'}\n",
    "    \n",
    "    dic = pyphen.Pyphen(lang='en_US')\n",
    "\n",
    "    def create_labels(token_list, feature_type='chars'):\n",
    "        labels = []\n",
    "        for token in token_list:\n",
    "            if feature_type == 'chars':\n",
    "                length = len(token)\n",
    "                if length <= 4: labels.append(0)\n",
    "                elif length <= 8: labels.append(1)\n",
    "                else: labels.append(2)\n",
    "            elif feature_type == 'syllables':\n",
    "                syllables = dic.inserted(token.lower()).count('-') + 1 if token.strip() else 0\n",
    "                if syllables <= 1: labels.append(0)\n",
    "                elif syllables <= 2: labels.append(1)\n",
    "                else: labels.append(2)\n",
    "        return labels\n",
    "\n",
    "    for sentence in tqdm(parsed_data, desc=\"Processing sentences\"):\n",
    "        tokens = [token['form'] for token in sentence]\n",
    "        words.append(tokens)\n",
    "        char_labels_data.append(create_labels(tokens, 'chars'))\n",
    "        syll_labels_data.append(create_labels(tokens, 'syllables'))\n",
    "\n",
    "    probing_dataset = Dataset.from_dict({\n",
    "        'tokens': words,\n",
    "        'char_labels': char_labels_data,\n",
    "        'syll_labels': syll_labels_data\n",
    "    })\n",
    "    \n",
    "    print(\"Dataset prepared for probing.\")\n",
    "    print(f\"Number of sentences in dataset: {len(probing_dataset)}\")\n",
    "    \n",
    "    SUBSET_SIZE = 2000\n",
    "    if len(probing_dataset) > SUBSET_SIZE:\n",
    "        probing_dataset = probing_dataset.shuffle(seed=42).select(range(SUBSET_SIZE))\n",
    "    \n",
    "    print(f\"Total sentences in probing subset: {len(probing_dataset)}\")\n",
    "    print(f\"Sample data: {probing_dataset[0]}\")\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error preparing dataset: {e}\")\n",
    "    exit()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85541c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Step 2: Probing Setup \n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n Step 2: Probing Setup \")\n",
    "\n",
    "model_name = 'distilbert-base-uncased'\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained(model_name)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "MODEL_DIR_FINE_TUNED = \"/home/sharmajidotdev/manish/models/readability\"\n",
    "PROBE_RESULTS_DIR = \"/home/sharmajidotdev/manish/probing_results\"\n",
    "os.makedirs(PROBE_RESULTS_DIR, exist_ok=True)\n",
    "\n",
    "\n",
    "# probing function \n",
    "def get_word_level_embeddings_single_sentence(sentence_tokens, labels_for_sentence, tokenizer, model, device):\n",
    "    base_bert_model = model.distilbert\n",
    "    base_bert_model.eval()\n",
    "\n",
    "    encoded_inputs = tokenizer(sentence_tokens, is_split_into_words=True, return_tensors='pt', padding=True, truncation=True, return_offsets_mapping=True, max_length=256)\n",
    "    input_ids, attention_mask = encoded_inputs['input_ids'].to(device), encoded_inputs['attention_mask'].to(device)\n",
    "    word_ids_list = encoded_inputs.word_ids()\n",
    "\n",
    "    if not isinstance(word_ids_list, list) or not word_ids_list or not labels_for_sentence: return None, None\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = base_bert_model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "    hidden_states = outputs.hidden_states\n",
    "    sentence_hidden_states_all_layers = [hs[0] for hs in hidden_states]\n",
    "    \n",
    "    word_to_subword_indices = {}\n",
    "    for token_idx, word_idx in enumerate(word_ids_list):\n",
    "        if word_idx is None or token_idx >= attention_mask.shape[1] or attention_mask[0, token_idx].item() == 0 or word_idx < 0: continue\n",
    "        if word_idx not in word_to_subword_indices: word_to_subword_indices[word_idx] = []\n",
    "        word_to_subword_indices[word_idx].append(token_idx)\n",
    "    if not word_to_subword_indices: return None, None\n",
    "    sorted_word_indices = sorted(word_to_subword_indices.keys())\n",
    "    if len(sorted_word_indices) != len(labels_for_sentence): return None, None\n",
    "    \n",
    "    current_sentence_word_embeddings_by_layer = [[] for _ in range(7)]\n",
    "    aligned_labels_for_sentence_output = []\n",
    "    \n",
    "    for original_word_idx in sorted_word_indices:\n",
    "        subword_token_indices = word_to_subword_indices[original_word_idx]\n",
    "        if not subword_token_indices: continue\n",
    "        for layer_idx in range(7):\n",
    "            if any(idx >= sentence_hidden_states_all_layers[layer_idx].shape[0] for idx in subword_token_indices): return None, None\n",
    "            subword_embs = sentence_hidden_states_all_layers[layer_idx][subword_token_indices, :]\n",
    "            current_sentence_word_embeddings_by_layer[layer_idx].append(subword_embs.mean(dim=0).cpu().numpy())\n",
    "        aligned_labels_for_sentence_output.append(labels_for_sentence[original_word_idx])\n",
    "    \n",
    "    processed_word_embeddings_tensors = []\n",
    "    for layer_idx in range(7):\n",
    "        if current_sentence_word_embeddings_by_layer[layer_idx]:\n",
    "            processed_word_embeddings_tensors.append(torch.from_numpy(np.vstack(current_sentence_word_embeddings_by_layer[layer_idx])).float())\n",
    "        else: return None, None\n",
    "    return processed_word_embeddings_tensors, aligned_labels_for_sentence_output\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de590366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Step 3: Probing Fine tuned models \n",
      "\n",
      " Probing Fine-Tuned Model from Fold 1 \n",
      "\n",
      "Extracting embeddings from FKGL-tuned model and training probes for NCHAR...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NCHAR Probing: 100%|██████████| 2000/2000 [00:17<00:00, 112.24it/s]\n",
      "/home/sharmajidotdev/manish/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/home/sharmajidotdev/manish/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/home/sharmajidotdev/manish/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/home/sharmajidotdev/manish/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/home/sharmajidotdev/manish/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/home/sharmajidotdev/manish/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/home/sharmajidotdev/manish/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting embeddings from FRE-tuned model and training probes for NSYLL...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NSYLL Probing: 100%|██████████| 2000/2000 [00:16<00:00, 118.66it/s]\n",
      "/home/sharmajidotdev/manish/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/home/sharmajidotdev/manish/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/home/sharmajidotdev/manish/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/home/sharmajidotdev/manish/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/home/sharmajidotdev/manish/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/home/sharmajidotdev/manish/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/home/sharmajidotdev/manish/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved probing results for Fold 1 to /home/sharmajidotdev/manish/probing_results/fold_0_probing_results.pkl\n",
      "\n",
      " Probing Fine-Tuned Model from Fold 2 \n",
      "\n",
      "Extracting embeddings from FKGL-tuned model and training probes for NCHAR...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NCHAR Probing: 100%|██████████| 2000/2000 [00:18<00:00, 109.95it/s]\n",
      "/home/sharmajidotdev/manish/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/home/sharmajidotdev/manish/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/home/sharmajidotdev/manish/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/home/sharmajidotdev/manish/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/home/sharmajidotdev/manish/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/home/sharmajidotdev/manish/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/home/sharmajidotdev/manish/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting embeddings from FRE-tuned model and training probes for NSYLL...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NSYLL Probing: 100%|██████████| 2000/2000 [00:16<00:00, 120.56it/s]\n",
      "/home/sharmajidotdev/manish/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/home/sharmajidotdev/manish/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/home/sharmajidotdev/manish/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/home/sharmajidotdev/manish/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/home/sharmajidotdev/manish/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/home/sharmajidotdev/manish/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/home/sharmajidotdev/manish/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved probing results for Fold 2 to /home/sharmajidotdev/manish/probing_results/fold_1_probing_results.pkl\n",
      "\n",
      " Probing Fine-Tuned Model from Fold 3 \n",
      "\n",
      "Extracting embeddings from FKGL-tuned model and training probes for NCHAR...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NCHAR Probing: 100%|██████████| 2000/2000 [00:17<00:00, 117.09it/s]\n",
      "/home/sharmajidotdev/manish/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/home/sharmajidotdev/manish/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/home/sharmajidotdev/manish/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/home/sharmajidotdev/manish/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/home/sharmajidotdev/manish/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/home/sharmajidotdev/manish/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/home/sharmajidotdev/manish/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting embeddings from FRE-tuned model and training probes for NSYLL...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NSYLL Probing: 100%|██████████| 2000/2000 [00:16<00:00, 120.14it/s]\n",
      "/home/sharmajidotdev/manish/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/home/sharmajidotdev/manish/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/home/sharmajidotdev/manish/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/home/sharmajidotdev/manish/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/home/sharmajidotdev/manish/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/home/sharmajidotdev/manish/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/home/sharmajidotdev/manish/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved probing results for Fold 3 to /home/sharmajidotdev/manish/probing_results/fold_2_probing_results.pkl\n",
      "\n",
      " Probing Fine-Tuned Model from Fold 4 \n",
      "\n",
      "Extracting embeddings from FKGL-tuned model and training probes for NCHAR...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NCHAR Probing: 100%|██████████| 2000/2000 [00:17<00:00, 115.95it/s]\n",
      "/home/sharmajidotdev/manish/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/home/sharmajidotdev/manish/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/home/sharmajidotdev/manish/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/home/sharmajidotdev/manish/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/home/sharmajidotdev/manish/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/home/sharmajidotdev/manish/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/home/sharmajidotdev/manish/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting embeddings from FRE-tuned model and training probes for NSYLL...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NSYLL Probing: 100%|██████████| 2000/2000 [00:17<00:00, 117.47it/s]\n",
      "/home/sharmajidotdev/manish/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/home/sharmajidotdev/manish/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/home/sharmajidotdev/manish/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/home/sharmajidotdev/manish/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/home/sharmajidotdev/manish/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/home/sharmajidotdev/manish/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/home/sharmajidotdev/manish/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved probing results for Fold 4 to /home/sharmajidotdev/manish/probing_results/fold_3_probing_results.pkl\n",
      "\n",
      " Probing Fine-Tuned Model from Fold 5 \n",
      "\n",
      "Extracting embeddings from FKGL-tuned model and training probes for NCHAR...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NCHAR Probing: 100%|██████████| 2000/2000 [00:16<00:00, 118.17it/s]\n",
      "/home/sharmajidotdev/manish/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/home/sharmajidotdev/manish/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/home/sharmajidotdev/manish/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/home/sharmajidotdev/manish/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/home/sharmajidotdev/manish/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/home/sharmajidotdev/manish/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/home/sharmajidotdev/manish/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting embeddings from FRE-tuned model and training probes for NSYLL...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NSYLL Probing: 100%|██████████| 2000/2000 [00:17<00:00, 117.34it/s]\n",
      "/home/sharmajidotdev/manish/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/home/sharmajidotdev/manish/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/home/sharmajidotdev/manish/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/home/sharmajidotdev/manish/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/home/sharmajidotdev/manish/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/home/sharmajidotdev/manish/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/home/sharmajidotdev/manish/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved probing results for Fold 5 to /home/sharmajidotdev/manish/probing_results/fold_4_probing_results.pkl\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n Step 3: Probing Fine tuned models \")\n",
    "\n",
    "probe_results_char_ft = {f\"layer_{i}\": {'accuracy': [], 'f1': []} for i in range(7)}\n",
    "probe_results_syll_ft = {f\"layer_{i}\": {'accuracy': [], 'f1': []} for i in range(7)}\n",
    "\n",
    "N_SPLITS = 5\n",
    "for fold_idx in range(N_SPLITS):\n",
    "    print(f\"\\n Probing Fine-Tuned Model from Fold {fold_idx + 1} \")\n",
    "\n",
    "    # loading fine-tuned models for FKGL and FRE for this fold\n",
    "    ft_model_fkgl = DistilBertForSequenceClassification.from_pretrained(\n",
    "        os.path.join(MODEL_DIR_FINE_TUNED, \"Fkgl\", f\"best_fold_{fold_idx}\"),\n",
    "        output_hidden_states=True\n",
    "    ).to(device)\n",
    "    \n",
    "    ft_model_fre = DistilBertForSequenceClassification.from_pretrained(\n",
    "        os.path.join(MODEL_DIR_FINE_TUNED, \"Fre\", f\"best_fold_{fold_idx}\"),\n",
    "        output_hidden_states=True\n",
    "    ).to(device)\n",
    "\n",
    "    #  probing for NCHAR on FKGL-tuned model \n",
    "    print(\"\\nExtracting embeddings from FKGL-tuned model and training probes for NCHAR...\")\n",
    "    all_embs_nchar_ft = [[] for _ in range(7)]\n",
    "    all_labels_nchar_ft = []\n",
    "    for i in tqdm(range(len(probing_dataset['tokens'])), desc=\"NCHAR Probing\"):\n",
    "        embs, labels = get_word_level_embeddings_single_sentence(probing_dataset['tokens'][i], probing_dataset['char_labels'][i], tokenizer, ft_model_fkgl, device)\n",
    "        if embs:\n",
    "            for l_idx, e_list in enumerate(embs):\n",
    "                all_embs_nchar_ft[l_idx].append(e_list)\n",
    "            all_labels_nchar_ft.extend(labels)\n",
    "    \n",
    "    concatenated_embs_nchar_ft = [torch.cat(embs, dim=0) for embs in all_embs_nchar_ft]\n",
    "    y_nchar_ft = np.array(all_labels_nchar_ft)\n",
    "\n",
    "    for l_idx in range(7):\n",
    "        X_train, X_val, y_train, y_val = train_test_split(concatenated_embs_nchar_ft[l_idx].cpu().numpy(), y_nchar_ft, test_size=0.2, stratify=y_nchar_ft)\n",
    "        probe = LogisticRegression(max_iter=1000, multi_class='multinomial', n_jobs=-1).fit(X_train, y_train)\n",
    "        y_pred = probe.predict(X_val)\n",
    "        probe_results_char_ft[f\"layer_{l_idx}\"]['accuracy'].append(accuracy_score(y_val, y_pred))\n",
    "        probe_results_char_ft[f\"layer_{l_idx}\"]['f1'].append(f1_score(y_val, y_pred, average='weighted'))\n",
    "\n",
    "    # probing for NSYLL on FRE-tuned model \n",
    "    print(\"\\nExtracting embeddings from FRE-tuned model and training probes for NSYLL...\")\n",
    "    all_embs_nsyll_ft = [[] for _ in range(7)]\n",
    "    all_labels_nsyll_ft = []\n",
    "    for i in tqdm(range(len(probing_dataset['tokens'])), desc=\"NSYLL Probing\"):\n",
    "        embs, labels = get_word_level_embeddings_single_sentence(probing_dataset['tokens'][i], probing_dataset['syll_labels'][i], tokenizer, ft_model_fre, device)\n",
    "        if embs:\n",
    "            for l_idx, e_list in enumerate(embs):\n",
    "                all_embs_nsyll_ft[l_idx].append(e_list)\n",
    "            all_labels_nsyll_ft.extend(labels)\n",
    "    \n",
    "    concatenated_embs_nsyll_ft = [torch.cat(embs, dim=0) for embs in all_embs_nsyll_ft]\n",
    "    y_nsyll_ft = np.array(all_labels_nsyll_ft)\n",
    "\n",
    "    for l_idx in range(7):\n",
    "        X_train, X_val, y_train, y_val = train_test_split(concatenated_embs_nsyll_ft[l_idx].cpu().numpy(), y_nsyll_ft, test_size=0.2, stratify=y_nsyll_ft)\n",
    "        probe = LogisticRegression(max_iter=1000, multi_class='multinomial', n_jobs=-1).fit(X_train, y_train)\n",
    "        y_pred = probe.predict(X_val)\n",
    "        probe_results_syll_ft[f\"layer_{l_idx}\"]['accuracy'].append(accuracy_score(y_val, y_pred))\n",
    "        probe_results_syll_ft[f\"layer_{l_idx}\"]['f1'].append(f1_score(y_val, y_pred, average='weighted'))\n",
    "    \n",
    "    # saving probing results for this fold\n",
    "    current_fold_results = {\n",
    "        'nchar': probe_results_char_ft,\n",
    "        'nsyll': probe_results_syll_ft\n",
    "    }\n",
    "    results_file_path = os.path.join(PROBE_RESULTS_DIR, f\"fold_{fold_idx}_probing_results.pkl\")\n",
    "    with open(results_file_path, 'wb') as f:\n",
    "        pickle.dump(current_fold_results, f)\n",
    "    print(f\"Saved probing results for Fold {fold_idx+1} to {results_file_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c182206b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Step 4: Final Summary \n",
      "Final Probing Results on Fine-Tuned Models (Average across 5 folds)\n",
      "------------------------------------------------------------------\n",
      "Number of Characters (NCHAR) Probe Accuracy: [np.float64(0.9429654335961188), np.float64(0.9330806549423893), np.float64(0.9196179502728926), np.float64(0.9050939963614312), np.float64(0.8928744693753791), np.float64(0.880230442692541), np.float64(0.8697392359005459)]\n",
      "Number of Characters (NCHAR) Probe F1-Score: [np.float64(0.9422132907847134), np.float64(0.9325676842977482), np.float64(0.9193849328727989), np.float64(0.904227673252182), np.float64(0.8920164315899548), np.float64(0.8789594188774214), np.float64(0.8679934563338982)]\n",
      "\n",
      "Number of Syllables (NSYLL) Probe Accuracy: [np.float64(0.9339902971497878), np.float64(0.9219526986052152), np.float64(0.9093086719223772), np.float64(0.9016373559733172), np.float64(0.8901152213462705), np.float64(0.876773802304427), np.float64(0.874711946634324)]\n",
      "Number of Syllables (NSYLL) Probe F1-Score: [np.float64(0.9336049306859439), np.float64(0.9217193102607016), np.float64(0.9087868748539882), np.float64(0.9010208317329218), np.float64(0.8894080481908594), np.float64(0.8752813087489584), np.float64(0.8726971732089547)]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n Step 4: Final Summary \")\n",
    "avg_probe_acc_char_ft = [np.mean(probe_results_char_ft[f\"layer_{i}\"]['accuracy']) for i in range(7)]\n",
    "avg_probe_f1_char_ft = [np.mean(probe_results_char_ft[f\"layer_{i}\"]['f1']) for i in range(7)]\n",
    "avg_probe_acc_syll_ft = [np.mean(probe_results_syll_ft[f\"layer_{i}\"]['accuracy']) for i in range(7)]\n",
    "avg_probe_f1_syll_ft = [np.mean(probe_results_syll_ft[f\"layer_{i}\"]['f1']) for i in range(7)]\n",
    "\n",
    "print(\"Final Probing Results on Fine-Tuned Models (Average across 5 folds)\")\n",
    "print(\"------------------------------------------------------------------\")\n",
    "print(\"Number of Characters (NCHAR) Probe Accuracy:\", avg_probe_acc_char_ft)\n",
    "print(\"Number of Characters (NCHAR) Probe F1-Score:\", avg_probe_f1_char_ft)\n",
    "print(\"\\nNumber of Syllables (NSYLL) Probe Accuracy:\", avg_probe_acc_syll_ft)\n",
    "print(\"Number of Syllables (NSYLL) Probe F1-Score:\", avg_probe_f1_syll_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ea2a9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successfully aggregated and saved final probing results to '/home/sharmajidotdev/manish/probing_results/final_probing_results.csv'.\n",
      "\n",
      "Final aggregated results:\n",
      "   feature  layer  accuracy        f1\n",
      "0    NCHAR      0  0.942399  0.941574\n",
      "1    NCHAR      1  0.932282  0.931789\n",
      "2    NCHAR      2  0.920740  0.920543\n",
      "3    NCHAR      3  0.903881  0.903061\n",
      "4    NCHAR      4  0.892137  0.891292\n",
      "5    NCHAR      5  0.881625  0.880414\n",
      "6    NCHAR      6  0.868941  0.867051\n",
      "7    NSYLL      0  0.933808  0.933462\n",
      "8    NSYLL      1  0.921720  0.921463\n",
      "9    NSYLL      2  0.909430  0.908869\n",
      "10   NSYLL      3  0.901334  0.900921\n",
      "11   NSYLL      4  0.890075  0.889426\n",
      "12   NSYLL      5  0.876087  0.874680\n",
      "13   NSYLL      6  0.874207  0.872226\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "RESULTS_DIR = \"/home/sharmajidotdev/manish/probing_results\"\n",
    "OUTPUT_CSV_PATH = \"/home/sharmajidotdev/manish/probing_results/final_probing_results.csv\"\n",
    "\n",
    "all_results = []\n",
    "\n",
    "#  dictionaries to store results across all folds\n",
    "results_nchar = {f\"layer_{i}\": {'accuracy': [], 'f1': []} for i in range(7)}\n",
    "results_nsyll = {f\"layer_{i}\": {'accuracy': [], 'f1': []} for i in range(7)}\n",
    "\n",
    "for fold_idx in range(5):\n",
    "    results_file_path = os.path.join(PROBE_RESULTS_DIR, f\"fold_{fold_idx}_probing_results.pkl\")\n",
    "    \n",
    "    try:\n",
    "        with open(results_file_path, 'rb') as f:\n",
    "            loaded_results = pickle.load(f)\n",
    "            \n",
    "            nchar_results_fold = loaded_results['nchar']\n",
    "            nsyll_results_fold = loaded_results['nsyll']\n",
    "            \n",
    "            for layer_key, metrics in nchar_results_fold.items():\n",
    "                results_nchar[layer_key]['accuracy'].extend(metrics['accuracy'])\n",
    "                results_nchar[layer_key]['f1'].extend(metrics['f1'])\n",
    "\n",
    "            for layer_key, metrics in nsyll_results_fold.items():\n",
    "                results_nsyll[layer_key]['accuracy'].extend(metrics['accuracy'])\n",
    "                results_nsyll[layer_key]['f1'].extend(metrics['f1'])\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Warning: Results file for fold {fold_idx+1} not found. Skipping.\")\n",
    "        \n",
    "final_records = []\n",
    "\n",
    "# processing NCHAR results\n",
    "for layer_idx in range(7):\n",
    "    layer_key = f\"layer_{layer_idx}\"\n",
    "    avg_acc = np.mean(results_nchar[layer_key]['accuracy'])\n",
    "    avg_f1 = np.mean(results_nchar[layer_key]['f1'])\n",
    "    final_records.append({'feature': 'NCHAR', 'layer': layer_idx, 'accuracy': avg_acc, 'f1': avg_f1})\n",
    "    \n",
    "# processing NSYLL results\n",
    "for layer_idx in range(7):\n",
    "    layer_key = f\"layer_{layer_idx}\"\n",
    "    avg_acc = np.mean(results_nsyll[layer_key]['accuracy'])\n",
    "    avg_f1 = np.mean(results_nsyll[layer_key]['f1'])\n",
    "    final_records.append({'feature': 'NSYLL', 'layer': layer_idx, 'accuracy': avg_acc, 'f1': avg_f1})\n",
    "\n",
    "results_df = pd.DataFrame(final_records)\n",
    "\n",
    "# saving  dataframe to CSV \n",
    "results_df.to_csv(OUTPUT_CSV_PATH, index=False)\n",
    "\n",
    "print(f\"\\nSuccessfully aggregated and saved final probing results to '{OUTPUT_CSV_PATH}'.\")\n",
    "print(\"\\nFinal aggregated results:\")\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa5bfac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded results from the pickle file.\n",
      "{'nchar': {'layer_0': {'accuracy': [0.9416312916919345], 'f1': [0.9408322353600702]}, 'layer_1': {'accuracy': [0.9307155852031535], 'f1': [0.9305592217162694]}, 'layer_2': {'accuracy': [0.9217707701637355], 'f1': [0.9218651595516834]}, 'layer_3': {'accuracy': [0.9010006064281383], 'f1': [0.9002654492524436]}, 'layer_4': {'accuracy': [0.8893268647665251], 'f1': [0.8886854566946439]}, 'layer_5': {'accuracy': [0.886294724075197], 'f1': [0.8848913181373872]}, 'layer_6': {'accuracy': [0.8673438447543966], 'f1': [0.8652369576201351]}}, 'nsyll': {'layer_0': {'accuracy': [0.9334445118253487], 'f1': [0.9331247530466945]}, 'layer_1': {'accuracy': [0.9225288053365677], 'f1': [0.922243583568802]}, 'layer_2': {'accuracy': [0.9096422073984233], 'f1': [0.9087742302785121]}, 'layer_3': {'accuracy': [0.8979684657368102], 'f1': [0.8975279297970576]}, 'layer_4': {'accuracy': [0.8887204366282595], 'f1': [0.8881481942534566]}, 'layer_5': {'accuracy': [0.8759854457246816], 'f1': [0.8752256069269841]}, 'layer_6': {'accuracy': [0.8728016979987872], 'f1': [0.8716233299050281]}}}\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "file_path = os.path.join(\"probing_results/fold_0_probing_results.pkl\") \n",
    "\n",
    "try:\n",
    "    with open(file_path, 'rb') as f:\n",
    "        loaded_results = pickle.load(f)\n",
    "\n",
    "    print(\"Successfully loaded results from the pickle file.\")\n",
    "    print(loaded_results)\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file '{file_path}' was not found.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while loading pickle file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74644ce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded results from the pickle file.\n",
      "{'nchar': {'layer_0': {'accuracy': [0.9416312916919345, 0.9445118253486962], 'f1': [0.9408322353600702, 0.9437649025969688]}, 'layer_1': {'accuracy': [0.9307155852031535, 0.9287446937537902], 'f1': [0.9305592217162694, 0.9280776765916897]}, 'layer_2': {'accuracy': [0.9217707701637355, 0.9241964827167981], 'f1': [0.9218651595516834, 0.9236568864905152]}, 'layer_3': {'accuracy': [0.9010006064281383, 0.9038811400849], 'f1': [0.9002654492524436, 0.9031709480028262]}, 'layer_4': {'accuracy': [0.8893268647665251, 0.8928138265615525], 'f1': [0.8886854566946439, 0.8918492119171202]}, 'layer_5': {'accuracy': [0.886294724075197, 0.8788659793814433], 'f1': [0.8848913181373872, 0.878243292700821]}, 'layer_6': {'accuracy': [0.8673438447543966, 0.8681018799272286], 'f1': [0.8652369576201351, 0.8662995501524938]}}, 'nsyll': {'layer_0': {'accuracy': [0.9334445118253487, 0.9343541540327471], 'f1': [0.9331247530466945, 0.9339967704756217]}, 'layer_1': {'accuracy': [0.9225288053365677, 0.9191934505761067], 'f1': [0.922243583568802, 0.9186055177070264]}, 'layer_2': {'accuracy': [0.9096422073984233, 0.9058520315342632], 'f1': [0.9087742302785121, 0.9054347667761977]}, 'layer_3': {'accuracy': [0.8979684657368102, 0.9032747119466343], 'f1': [0.8975279297970576, 0.9033282460772691]}, 'layer_4': {'accuracy': [0.8887204366282595, 0.8903881140084899], 'f1': [0.8881481942534566, 0.890161034814665]}, 'layer_5': {'accuracy': [0.8759854457246816, 0.8744693753790176], 'f1': [0.8752256069269841, 0.8725897550603668]}, 'layer_6': {'accuracy': [0.8728016979987872, 0.874620982413584], 'f1': [0.8716233299050281, 0.8718291314976979]}}}\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "file_path = os.path.join(\"probing_results/fold_1_probing_results.pkl\") \n",
    "\n",
    "try:\n",
    "    with open(file_path, 'rb') as f:\n",
    "        loaded_results = pickle.load(f)\n",
    "\n",
    "    print(\"Successfully loaded results from the pickle file.\")\n",
    "    print(loaded_results)\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file '{file_path}' was not found.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while loading pickle file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd05c8c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded results from the pickle file.\n",
      "{'nchar': {'layer_0': {'accuracy': [0.9416312916919345, 0.9445118253486962, 0.9387507580351728], 'f1': [0.9408322353600702, 0.9437649025969688, 0.9374751343663253]}, 'layer_1': {'accuracy': [0.9307155852031535, 0.9287446937537902, 0.9364766525166768], 'f1': [0.9305592217162694, 0.9280776765916897, 0.9357339304912485]}, 'layer_2': {'accuracy': [0.9217707701637355, 0.9241964827167981, 0.9197998787143723], 'f1': [0.9218651595516834, 0.9236568864905152, 0.9196006094421237]}, 'layer_3': {'accuracy': [0.9010006064281383, 0.9038811400849, 0.9044875682231656], 'f1': [0.9002654492524436, 0.9031709480028262, 0.9035549008356476]}, 'layer_4': {'accuracy': [0.8893268647665251, 0.8928138265615525, 0.8938750758035173], 'f1': [0.8886854566946439, 0.8918492119171202, 0.8931199594719471]}, 'layer_5': {'accuracy': [0.886294724075197, 0.8788659793814433, 0.8784111582777441], 'f1': [0.8848913181373872, 0.878243292700821, 0.8771290272477056]}, 'layer_6': {'accuracy': [0.8673438447543966, 0.8681018799272286, 0.8676470588235294], 'f1': [0.8652369576201351, 0.8662995501524938, 0.8653783829024048]}}, 'nsyll': {'layer_0': {'accuracy': [0.9334445118253487, 0.9343541540327471, 0.9314736203759855], 'f1': [0.9331247530466945, 0.9339967704756217, 0.9312456236738571]}, 'layer_1': {'accuracy': [0.9225288053365677, 0.9191934505761067, 0.9235900545785325], 'f1': [0.922243583568802, 0.9186055177070264, 0.9237919878877844]}, 'layer_2': {'accuracy': [0.9096422073984233, 0.9058520315342632, 0.915554881746513], 'f1': [0.9087742302785121, 0.9054347667761977, 0.9151914702809477]}, 'layer_3': {'accuracy': [0.8979684657368102, 0.9032747119466343, 0.9057004244996968], 'f1': [0.8975279297970576, 0.9033282460772691, 0.9054104969917919]}, 'layer_4': {'accuracy': [0.8887204366282595, 0.8903881140084899, 0.8925106124924197], 'f1': [0.8881481942534566, 0.890161034814665, 0.8911191259974585]}, 'layer_5': {'accuracy': [0.8759854457246816, 0.8744693753790176, 0.8771983020012128], 'f1': [0.8752256069269841, 0.8725897550603668, 0.8752338977989822]}, 'layer_6': {'accuracy': [0.8728016979987872, 0.874620982413584, 0.873862947240752], 'f1': [0.8716233299050281, 0.8718291314976979, 0.8715198103434505]}}}\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "file_path = os.path.join(\"probing_results/fold_2_probing_results.pkl\") \n",
    "\n",
    "try:\n",
    "    with open(file_path, 'rb') as f:\n",
    "        loaded_results = pickle.load(f)\n",
    "\n",
    "    print(\"Successfully loaded results from the pickle file.\")\n",
    "    print(loaded_results)\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file '{file_path}' was not found.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while loading pickle file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49844ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded results from the pickle file.\n",
      "{'nchar': {'layer_0': {'accuracy': [0.9416312916919345, 0.9445118253486962, 0.9387507580351728, 0.9436021831412977], 'f1': [0.9408322353600702, 0.9437649025969688, 0.9374751343663253, 0.9429679840611409]}, 'layer_1': {'accuracy': [0.9307155852031535, 0.9287446937537902, 0.9364766525166768, 0.9367798665858096], 'f1': [0.9305592217162694, 0.9280776765916897, 0.9357339304912485, 0.9360585720311106]}, 'layer_2': {'accuracy': [0.9217707701637355, 0.9241964827167981, 0.9197998787143723, 0.9137355973317162], 'f1': [0.9218651595516834, 0.9236568864905152, 0.9196006094421237, 0.9135820371152626]}, 'layer_3': {'accuracy': [0.9010006064281383, 0.9038811400849, 0.9044875682231656, 0.9081261370527592], 'f1': [0.9002654492524436, 0.9031709480028262, 0.9035549008356476, 0.9070907098482137]}, 'layer_4': {'accuracy': [0.8893268647665251, 0.8928138265615525, 0.8938750758035173, 0.8941782898726501], 'f1': [0.8886854566946439, 0.8918492119171202, 0.8931199594719471, 0.8927668353079489]}, 'layer_5': {'accuracy': [0.886294724075197, 0.8788659793814433, 0.8784111582777441, 0.8846270466949666], 'f1': [0.8848913181373872, 0.878243292700821, 0.8771290272477056, 0.8828639342457612]}, 'layer_6': {'accuracy': [0.8673438447543966, 0.8681018799272286, 0.8676470588235294, 0.8764402668283808], 'f1': [0.8652369576201351, 0.8662995501524938, 0.8653783829024048, 0.8751912154942154]}}, 'nsyll': {'layer_0': {'accuracy': [0.9334445118253487, 0.9343541540327471, 0.9314736203759855, 0.9373862947240752], 'f1': [0.9331247530466945, 0.9339967704756217, 0.9312456236738571, 0.936921409709119]}, 'layer_1': {'accuracy': [0.9225288053365677, 0.9191934505761067, 0.9235900545785325, 0.9211643420254699], 'f1': [0.922243583568802, 0.9186055177070264, 0.9237919878877844, 0.9209709040842193]}, 'layer_2': {'accuracy': [0.9096422073984233, 0.9058520315342632, 0.915554881746513, 0.90767131594906], 'f1': [0.9087742302785121, 0.9054347667761977, 0.9151914702809477, 0.9073193390466417]}, 'layer_3': {'accuracy': [0.8979684657368102, 0.9032747119466343, 0.9057004244996968, 0.8987265009096422], 'f1': [0.8975279297970576, 0.9033282460772691, 0.9054104969917919, 0.8977928483995455]}, 'layer_4': {'accuracy': [0.8887204366282595, 0.8903881140084899, 0.8925106124924197, 0.8894784718010915], 'f1': [0.8881481942534566, 0.890161034814665, 0.8911191259974585, 0.8890411862201234]}, 'layer_5': {'accuracy': [0.8759854457246816, 0.8744693753790176, 0.8771983020012128, 0.8756822316555488], 'f1': [0.8752256069269841, 0.8725897550603668, 0.8752338977989822, 0.8746514503532486]}, 'layer_6': {'accuracy': [0.8728016979987872, 0.874620982413584, 0.873862947240752, 0.8767434808975136], 'f1': [0.8716233299050281, 0.8718291314976979, 0.8715198103434505, 0.8748805934717793]}}}\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "file_path = os.path.join(\"probing_results/fold_3_probing_results.pkl\") \n",
    "\n",
    "try:\n",
    "    with open(file_path, 'rb') as f:\n",
    "        loaded_results = pickle.load(f)\n",
    "\n",
    "    # printing  contents of  dictionary\n",
    "    print(\"Successfully loaded results from the pickle file.\")\n",
    "    print(loaded_results)\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file '{file_path}' was not found.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while loading pickle file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55351d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded results from the pickle file.\n",
      "{'nchar': {'layer_0': {'accuracy': [0.9416312916919345, 0.9445118253486962, 0.9387507580351728, 0.9436021831412977, 0.946331109763493], 'f1': [0.9408322353600702, 0.9437649025969688, 0.9374751343663253, 0.9429679840611409, 0.9460261975390621]}, 'layer_1': {'accuracy': [0.9307155852031535, 0.9287446937537902, 0.9364766525166768, 0.9367798665858096, 0.9326864766525167], 'f1': [0.9305592217162694, 0.9280776765916897, 0.9357339304912485, 0.9360585720311106, 0.9324090206584222]}, 'layer_2': {'accuracy': [0.9217707701637355, 0.9241964827167981, 0.9197998787143723, 0.9137355973317162, 0.9185870224378411], 'f1': [0.9218651595516834, 0.9236568864905152, 0.9196006094421237, 0.9135820371152626, 0.9182199717644092]}, 'layer_3': {'accuracy': [0.9010006064281383, 0.9038811400849, 0.9044875682231656, 0.9081261370527592, 0.9079745300181928], 'f1': [0.9002654492524436, 0.9031709480028262, 0.9035549008356476, 0.9070907098482137, 0.9070563583217789]}, 'layer_4': {'accuracy': [0.8893268647665251, 0.8928138265615525, 0.8938750758035173, 0.8941782898726501, 0.8941782898726501], 'f1': [0.8886854566946439, 0.8918492119171202, 0.8931199594719471, 0.8927668353079489, 0.8936606945581135]}, 'layer_5': {'accuracy': [0.886294724075197, 0.8788659793814433, 0.8784111582777441, 0.8846270466949666, 0.8729533050333536], 'f1': [0.8848913181373872, 0.878243292700821, 0.8771290272477056, 0.8828639342457612, 0.8716695220554312]}, 'layer_6': {'accuracy': [0.8673438447543966, 0.8681018799272286, 0.8676470588235294, 0.8764402668283808, 0.8691631291691935], 'f1': [0.8652369576201351, 0.8662995501524938, 0.8653783829024048, 0.8751912154942154, 0.867861175500242]}}, 'nsyll': {'layer_0': {'accuracy': [0.9334445118253487, 0.9343541540327471, 0.9314736203759855, 0.9373862947240752, 0.9332929047907823], 'f1': [0.9331247530466945, 0.9339967704756217, 0.9312456236738571, 0.936921409709119, 0.9327360965244268]}, 'layer_1': {'accuracy': [0.9225288053365677, 0.9191934505761067, 0.9235900545785325, 0.9211643420254699, 0.9232868405093997], 'f1': [0.922243583568802, 0.9186055177070264, 0.9237919878877844, 0.9209709040842193, 0.9229845580556763]}, 'layer_2': {'accuracy': [0.9096422073984233, 0.9058520315342632, 0.915554881746513, 0.90767131594906, 0.9078229229836264], 'f1': [0.9087742302785121, 0.9054347667761977, 0.9151914702809477, 0.9073193390466417, 0.9072145678876429]}, 'layer_3': {'accuracy': [0.8979684657368102, 0.9032747119466343, 0.9057004244996968, 0.8987265009096422, 0.9025166767738023], 'f1': [0.8975279297970576, 0.9033282460772691, 0.9054104969917919, 0.8977928483995455, 0.9010446373989441]}, 'layer_4': {'accuracy': [0.8887204366282595, 0.8903881140084899, 0.8925106124924197, 0.8894784718010915, 0.8894784718010915], 'f1': [0.8881481942534566, 0.890161034814665, 0.8911191259974585, 0.8890411862201234, 0.8885706996685934]}, 'layer_5': {'accuracy': [0.8759854457246816, 0.8744693753790176, 0.8771983020012128, 0.8756822316555488, 0.8805336567616737], 'f1': [0.8752256069269841, 0.8725897550603668, 0.8752338977989822, 0.8746514503532486, 0.8787058336052099]}, 'layer_6': {'accuracy': [0.8728016979987872, 0.874620982413584, 0.873862947240752, 0.8767434808975136, 0.8755306246209824], 'f1': [0.8716233299050281, 0.8718291314976979, 0.8715198103434505, 0.8748805934717793, 0.8736330008268175]}}}\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "file_path = os.path.join(\"probing_results/fold_4_probing_results.pkl\") \n",
    "\n",
    "try:\n",
    "    with open(file_path, 'rb') as f:\n",
    "        loaded_results = pickle.load(f)\n",
    "    print(\"Successfully loaded results from the pickle file.\")\n",
    "    print(loaded_results)\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file '{file_path}' was not found.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while loading pickle file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41d7ccc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
