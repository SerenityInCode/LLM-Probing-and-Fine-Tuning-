{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/manisha/DATA/dissertation_project/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertModel, BertTokenizerFast\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "import pandas as pd\n",
    "import requests\n",
    "import textstat\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Loading dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/UniversalDependencies/UD_English-EWT/master/en_ewt-ud-train.conllu\"\n",
    "response = requests.get(url)\n",
    "conllu_text = response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "current_sentence = []\n",
    "\n",
    "for line in conllu_text.splitlines():\n",
    "    if line.startswith(\"# text = \"):\n",
    "        if current_sentence:\n",
    "            sentences.append(\" \".join(current_sentence))\n",
    "            current_sentence = []\n",
    "        sentence_text = line.replace(\"# text = \", \"\").strip()\n",
    "        current_sentence.append(sentence_text)\n",
    "    elif line == \"\":\n",
    "        if current_sentence:\n",
    "            sentences.append(\" \".join(current_sentence))\n",
    "            current_sentence = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sentences extracted: 12544\n",
      "Calculating FKGL and FRE scores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing sentences: 100%|██████████| 12544/12544 [00:01<00:00, 6706.55it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Example sentence: Al-Zaman : American forces killed Shaikh Abdullah al-Ani, the preacher at the mosque in the town of Qaim, near the Syrian border.\n",
      " FKGL: 10.580952380952379\n",
      " FRE: 56.6057142857143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "fkgl_scores = []\n",
    "fre_scores = []\n",
    "\n",
    "print(f\"Total sentences extracted: {len(sentences)}\")\n",
    "print(\"Calculating FKGL and FRE scores...\")\n",
    "\n",
    "for sent in tqdm(sentences, desc=\"Processing sentences\"):\n",
    "    if sent and sent.strip():\n",
    "        fkgl = textstat.flesch_kincaid_grade(sent)\n",
    "        fre = textstat.flesch_reading_ease(sent)\n",
    "    else:\n",
    "        fkgl = 0.0\n",
    "        fre = 0.0\n",
    "    fkgl_scores.append(fkgl)\n",
    "    fre_scores.append(fre)\n",
    "\n",
    "print(f\"\\n Example sentence: {sentences[0]}\")\n",
    "print(f\" FKGL: {fkgl_scores[0]}\")\n",
    "print(f\" FRE: {fre_scores[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSdpaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "model_name = \"bert-base-uncased\"\n",
    "tokenizer = BertTokenizerFast.from_pretrained(model_name)\n",
    "model = BertModel.from_pretrained(model_name, output_hidden_states=True)\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_embedding(sentence):\n",
    "    encoded = tokenizer(\n",
    "        sentence,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        max_length=128,\n",
    "        padding=\"max_length\"\n",
    "    )\n",
    "    input_ids = encoded[\"input_ids\"].to(device)\n",
    "    attention_mask = encoded[\"attention_mask\"].to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        hidden_states = outputs.hidden_states  \n",
    "    \n",
    "    all_layer_embeddings = []\n",
    "    for layer in hidden_states:\n",
    "        token_embeddings = layer[0]  \n",
    "        mask = attention_mask[0].unsqueeze(-1).expand(token_embeddings.size()).bool()\n",
    "        \n",
    "        valid_embeddings = token_embeddings[mask].view(-1, token_embeddings.size(-1))\n",
    "        sentence_embedding = valid_embeddings.mean(dim=0).cpu().numpy()\n",
    "        all_layer_embeddings.append(sentence_embedding)\n",
    "    return all_layer_embeddings \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding sentences: 100%|██████████| 12544/12544 [1:32:46<00:00,  2.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings shape per layer example:\n",
      "Layer 0 embedding shape: (12544, 768)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "all_sentence_embeddings_by_layer = [[] for _ in range(model.config.num_hidden_layers + 1)]\n",
    "\n",
    "for sent in tqdm(sentences, desc=\"Embedding sentences\"):\n",
    "    sentence_embs = get_sentence_embedding(sent)\n",
    "    for layer_idx, emb in enumerate(sentence_embs):\n",
    "        all_sentence_embeddings_by_layer[layer_idx].append(emb)\n",
    "\n",
    "# Converting to numpy arrays\n",
    "for i in range(len(all_sentence_embeddings_by_layer)):\n",
    "    all_sentence_embeddings_by_layer[i] = np.vstack(all_sentence_embeddings_by_layer[i])\n",
    "\n",
    "print(\"Embeddings shape per layer example:\")\n",
    "print(f\"Layer 0 embedding shape: {all_sentence_embeddings_by_layer[0].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Layer 0 \n",
      "Fold 1: FKGL MAE=3.525, R2=0.584 | FRE MAE=24.852, R2=0.551\n",
      "Fold 2: FKGL MAE=3.687, R2=0.546 | FRE MAE=25.813, R2=0.521\n",
      "Fold 3: FKGL MAE=3.449, R2=0.558 | FRE MAE=23.927, R2=0.490\n",
      "Fold 4: FKGL MAE=3.594, R2=0.489 | FRE MAE=25.151, R2=0.457\n",
      "Fold 5: FKGL MAE=3.462, R2=0.497 | FRE MAE=24.233, R2=0.449\n",
      "\n",
      " Layer 1 \n",
      "Fold 1: FKGL MAE=3.325, R2=0.642 | FRE MAE=23.239, R2=0.611\n",
      "Fold 2: FKGL MAE=3.490, R2=0.606 | FRE MAE=24.316, R2=0.581\n",
      "Fold 3: FKGL MAE=3.372, R2=0.588 | FRE MAE=23.441, R2=0.522\n",
      "Fold 4: FKGL MAE=3.453, R2=0.550 | FRE MAE=24.143, R2=0.518\n",
      "Fold 5: FKGL MAE=3.381, R2=0.539 | FRE MAE=23.797, R2=0.492\n",
      "\n",
      " Layer 2 \n",
      "Fold 1: FKGL MAE=3.304, R2=0.660 | FRE MAE=23.136, R2=0.630\n",
      "Fold 2: FKGL MAE=3.498, R2=0.623 | FRE MAE=24.330, R2=0.603\n",
      "Fold 3: FKGL MAE=3.360, R2=0.589 | FRE MAE=23.401, R2=0.525\n",
      "Fold 4: FKGL MAE=3.438, R2=0.578 | FRE MAE=24.038, R2=0.551\n",
      "Fold 5: FKGL MAE=3.342, R2=0.565 | FRE MAE=23.290, R2=0.522\n",
      "\n",
      " Layer 3 \n",
      "Fold 1: FKGL MAE=3.236, R2=0.686 | FRE MAE=22.907, R2=0.656\n",
      "Fold 2: FKGL MAE=3.573, R2=0.640 | FRE MAE=25.015, R2=0.621\n",
      "Fold 3: FKGL MAE=3.503, R2=0.579 | FRE MAE=24.209, R2=0.518\n",
      "Fold 4: FKGL MAE=3.525, R2=0.589 | FRE MAE=24.510, R2=0.565\n",
      "Fold 5: FKGL MAE=3.406, R2=0.572 | FRE MAE=23.901, R2=0.532\n",
      "\n",
      " Layer 4 \n",
      "Fold 1: FKGL MAE=3.082, R2=0.716 | FRE MAE=21.835, R2=0.690\n",
      "Fold 2: FKGL MAE=3.405, R2=0.677 | FRE MAE=23.812, R2=0.661\n",
      "Fold 3: FKGL MAE=3.319, R2=0.600 | FRE MAE=22.979, R2=0.540\n",
      "Fold 4: FKGL MAE=3.307, R2=0.632 | FRE MAE=22.989, R2=0.610\n",
      "Fold 5: FKGL MAE=3.235, R2=0.610 | FRE MAE=22.949, R2=0.571\n",
      "\n",
      " Layer 5 \n",
      "Fold 1: FKGL MAE=3.214, R2=0.702 | FRE MAE=22.947, R2=0.672\n",
      "Fold 2: FKGL MAE=3.458, R2=0.673 | FRE MAE=24.264, R2=0.654\n",
      "Fold 3: FKGL MAE=3.317, R2=0.598 | FRE MAE=23.024, R2=0.534\n",
      "Fold 4: FKGL MAE=3.398, R2=0.628 | FRE MAE=23.720, R2=0.604\n",
      "Fold 5: FKGL MAE=3.343, R2=0.611 | FRE MAE=23.598, R2=0.572\n",
      "\n",
      " Layer 6 \n",
      "Fold 1: FKGL MAE=3.267, R2=0.703 | FRE MAE=23.099, R2=0.674\n",
      "Fold 2: FKGL MAE=3.457, R2=0.682 | FRE MAE=24.190, R2=0.664\n",
      "Fold 3: FKGL MAE=3.398, R2=0.589 | FRE MAE=23.770, R2=0.521\n",
      "Fold 4: FKGL MAE=3.436, R2=0.645 | FRE MAE=23.955, R2=0.623\n",
      "Fold 5: FKGL MAE=3.414, R2=0.616 | FRE MAE=24.038, R2=0.581\n",
      "\n",
      " Layer 7 \n",
      "Fold 1: FKGL MAE=3.328, R2=0.693 | FRE MAE=23.370, R2=0.665\n",
      "Fold 2: FKGL MAE=3.453, R2=0.698 | FRE MAE=24.175, R2=0.680\n",
      "Fold 3: FKGL MAE=3.416, R2=0.597 | FRE MAE=23.645, R2=0.535\n",
      "Fold 4: FKGL MAE=3.411, R2=0.647 | FRE MAE=23.703, R2=0.626\n",
      "Fold 5: FKGL MAE=3.458, R2=0.614 | FRE MAE=24.314, R2=0.580\n",
      "\n",
      " Layer 8 \n",
      "Fold 1: FKGL MAE=3.498, R2=0.685 | FRE MAE=24.672, R2=0.658\n",
      "Fold 2: FKGL MAE=3.504, R2=0.705 | FRE MAE=24.445, R2=0.690\n",
      "Fold 3: FKGL MAE=3.492, R2=0.577 | FRE MAE=24.417, R2=0.509\n",
      "Fold 4: FKGL MAE=3.534, R2=0.646 | FRE MAE=24.506, R2=0.625\n",
      "Fold 5: FKGL MAE=3.490, R2=0.618 | FRE MAE=24.411, R2=0.584\n",
      "\n",
      " Layer 9 \n",
      "Fold 1: FKGL MAE=3.551, R2=0.684 | FRE MAE=25.063, R2=0.656\n",
      "Fold 2: FKGL MAE=3.531, R2=0.701 | FRE MAE=24.845, R2=0.684\n",
      "Fold 3: FKGL MAE=3.552, R2=0.563 | FRE MAE=24.540, R2=0.499\n",
      "Fold 4: FKGL MAE=3.598, R2=0.636 | FRE MAE=25.057, R2=0.613\n",
      "Fold 5: FKGL MAE=3.483, R2=0.607 | FRE MAE=24.350, R2=0.573\n",
      "\n",
      " Layer 10 \n",
      "Fold 1: FKGL MAE=3.649, R2=0.676 | FRE MAE=25.786, R2=0.647\n",
      "Fold 2: FKGL MAE=3.650, R2=0.687 | FRE MAE=25.760, R2=0.671\n",
      "Fold 3: FKGL MAE=3.630, R2=0.552 | FRE MAE=25.163, R2=0.486\n",
      "Fold 4: FKGL MAE=3.727, R2=0.623 | FRE MAE=25.913, R2=0.603\n",
      "Fold 5: FKGL MAE=3.621, R2=0.585 | FRE MAE=25.630, R2=0.548\n",
      "\n",
      " Layer 11 \n",
      "Fold 1: FKGL MAE=3.691, R2=0.670 | FRE MAE=25.889, R2=0.646\n",
      "Fold 2: FKGL MAE=3.734, R2=0.674 | FRE MAE=25.885, R2=0.661\n",
      "Fold 3: FKGL MAE=3.738, R2=0.534 | FRE MAE=25.695, R2=0.471\n",
      "Fold 4: FKGL MAE=3.799, R2=0.613 | FRE MAE=26.198, R2=0.592\n",
      "Fold 5: FKGL MAE=3.613, R2=0.580 | FRE MAE=25.460, R2=0.542\n",
      "\n",
      " Layer 12 \n",
      "Fold 1: FKGL MAE=3.723, R2=0.661 | FRE MAE=25.911, R2=0.637\n",
      "Fold 2: FKGL MAE=3.885, R2=0.649 | FRE MAE=26.888, R2=0.634\n",
      "Fold 3: FKGL MAE=3.857, R2=0.522 | FRE MAE=26.585, R2=0.456\n",
      "Fold 4: FKGL MAE=3.932, R2=0.593 | FRE MAE=27.040, R2=0.572\n",
      "Fold 5: FKGL MAE=3.770, R2=0.545 | FRE MAE=26.611, R2=0.504\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "results = []\n",
    "\n",
    "for layer_idx, embeddings in enumerate(all_sentence_embeddings_by_layer):\n",
    "    print(f\"\\n Layer {layer_idx} \")\n",
    "    \n",
    "    fkgl_maes = []\n",
    "    fkgl_r2s = []\n",
    "    fre_maes = []\n",
    "    fre_r2s = []\n",
    "    \n",
    "    for fold, (train_idx, test_idx) in enumerate(kf.split(embeddings)):\n",
    "        X_train, X_test = embeddings[train_idx], embeddings[test_idx]\n",
    "        y_train_fkgl, y_test_fkgl = np.array(fkgl_scores)[train_idx], np.array(fkgl_scores)[test_idx]\n",
    "        y_train_fre, y_test_fre = np.array(fre_scores)[train_idx], np.array(fre_scores)[test_idx]\n",
    "        \n",
    "        # FKGL regression\n",
    "        reg_fkgl = LinearRegression()\n",
    "        reg_fkgl.fit(X_train, y_train_fkgl)\n",
    "        pred_fkgl = reg_fkgl.predict(X_test)\n",
    "        \n",
    "        mae_fkgl = mean_absolute_error(y_test_fkgl, pred_fkgl)\n",
    "        r2_fkgl = r2_score(y_test_fkgl, pred_fkgl)\n",
    "        \n",
    "        fkgl_maes.append(mae_fkgl)\n",
    "        fkgl_r2s.append(r2_fkgl)\n",
    "        \n",
    "        # FRE regression\n",
    "        reg_fre = LinearRegression()\n",
    "        reg_fre.fit(X_train, y_train_fre)\n",
    "        pred_fre = reg_fre.predict(X_test)\n",
    "        \n",
    "        mae_fre = mean_absolute_error(y_test_fre, pred_fre)\n",
    "        r2_fre = r2_score(y_test_fre, pred_fre)\n",
    "        \n",
    "        fre_maes.append(mae_fre)\n",
    "        fre_r2s.append(r2_fre)\n",
    "        \n",
    "        print(f\"Fold {fold+1}: FKGL MAE={mae_fkgl:.3f}, R2={r2_fkgl:.3f} | FRE MAE={mae_fre:.3f}, R2={r2_fre:.3f}\")\n",
    "        \n",
    "        # saving fold results\n",
    "        results.append({\n",
    "            \"layer\": layer_idx,\n",
    "            \"fold\": fold + 1,\n",
    "            \"fkgl_mae\": mae_fkgl,\n",
    "            \"fkgl_r2\": r2_fkgl,\n",
    "            \"fre_mae\": mae_fre,\n",
    "            \"fre_r2\": r2_fre,\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Regression results saved to 'bert_readability_regression_results.csv'\n"
     ]
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv(\"bert_readability_regression_results.csv\", index=False)\n",
    "print(\"\\n Regression results saved to 'bert_readability_regression_results.csv'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
