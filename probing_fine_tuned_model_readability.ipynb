{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Data Preparation for Probing \n",
      "Loading data from local file: en_ewt-ud-train.conllu...\n",
      "Total sentences extracted: 12544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing sentences: 100%|██████████| 2000/2000 [00:00<00:00, 10182.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example sentence: How was the play?\n",
      "FKGL: -2.2299999999999986\n",
      "FRE: 118.17500000000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import textstat\n",
    "import conllu\n",
    "import requests\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from transformers import (\n",
    "    DistilBertTokenizerFast,\n",
    "    DistilBertForSequenceClassification,\n",
    "    DistilBertModel\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print(\"Step 1: Data Preparation for Probing \")\n",
    "file_path = \"en_ewt-ud-train.conllu\"\n",
    "\n",
    "try:\n",
    "    print(f\"Loading data from local file: {file_path}...\")\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        conllu_text = f.read()\n",
    "    \n",
    "    sentences = []\n",
    "    fkgl_scores = []\n",
    "    fre_scores = []\n",
    "    \n",
    "    for line in conllu_text.splitlines():\n",
    "        if line.startswith(\"# text = \"):\n",
    "            sentences.append(line.replace(\"# text = \", \"\").strip())\n",
    "    \n",
    "    print(f\"Total sentences extracted: {len(sentences)}\")\n",
    "\n",
    "    SUBSET_SIZE = 2000\n",
    "    if len(sentences) > SUBSET_SIZE:\n",
    "        # shuffling indices and selecting subset\n",
    "        indices = np.arange(len(sentences))\n",
    "        np.random.seed(42)\n",
    "        np.random.shuffle(indices)\n",
    "        sentences = [sentences[i] for i in indices[:SUBSET_SIZE]]\n",
    "    \n",
    "    for sent in tqdm(sentences, desc=\"Processing sentences\"):\n",
    "        if sent and sent.strip():\n",
    "            fkgl = textstat.flesch_kincaid_grade(sent)\n",
    "            fre = textstat.flesch_reading_ease(sent)\n",
    "        else:\n",
    "            fkgl = 0.0\n",
    "            fre = 0.0\n",
    "        fkgl_scores.append(fkgl)\n",
    "        fre_scores.append(fre)\n",
    "        \n",
    "    print(f\"\\nExample sentence: {sentences[0]}\")\n",
    "    print(f\"FKGL: {fkgl_scores[0]}\")\n",
    "    print(f\"FRE: {fre_scores[0]}\")\n",
    "\n",
    "    probing_dataset = Dataset.from_dict({\n",
    "        'text': sentences,\n",
    "        'fkgl_score': fkgl_scores,\n",
    "        'fre_score': fre_scores\n",
    "    })\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error preparing dataset: {e}\")\n",
    "    exit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Step 2: Probing Setup\n",
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n Step 2: Probing Setup\")\n",
    "model_name = 'distilbert-base-uncased'\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained(model_name)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "MODEL_DIR_FINE_TUNED = \"/media/manisha/DATA/dissertation_project/models/readability\"\n",
    "PROBE_RESULTS_DIR = \"/media/manisha/DATA/dissertation_project/probing_readability_results\"\n",
    "os.makedirs(PROBE_RESULTS_DIR, exist_ok=True)\n",
    "\n",
    "\n",
    "def get_sentence_embedding(sentence, model):\n",
    "    encoded = tokenizer(\n",
    "        sentence,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        max_length=256,\n",
    "        padding=\"max_length\"\n",
    "    )\n",
    "    input_ids = encoded[\"input_ids\"].to(device)\n",
    "    attention_mask = encoded[\"attention_mask\"].to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, output_hidden_states=True)\n",
    "        hidden_states = outputs.hidden_states\n",
    "    \n",
    "    all_layer_embeddings = []\n",
    "    for layer in hidden_states:\n",
    "        token_embeddings = layer[0]  # remove batch dim\n",
    "        sentence_embedding = token_embeddings.mean(dim=0).cpu().numpy()\n",
    "        all_layer_embeddings.append(sentence_embedding)\n",
    "    return all_layer_embeddings\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Step 3: Probing Fine-Tuned Models \n",
      "\n",
      " Probing Fine-Tuned Model from Fold 1 \n",
      "\n",
      "Extracting embeddings from FKGL-tuned model and training probes for FKGL...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FKGL Probing: 100%|██████████| 2000/2000 [12:37<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting embeddings from FRE-tuned model and training probes for FRE...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FRE Probing: 100%|██████████| 2000/2000 [13:24<00:00,  2.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved probing results for Fold 1 to /media/manisha/DATA/dissertation_project/probing_readability_results/fold_0_probing_results.pkl\n",
      "\n",
      " Probing Fine-Tuned Model from Fold 2 \n",
      "\n",
      "Extracting embeddings from FKGL-tuned model and training probes for FKGL...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FKGL Probing: 100%|██████████| 2000/2000 [13:39<00:00,  2.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting embeddings from FRE-tuned model and training probes for FRE...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FRE Probing: 100%|██████████| 2000/2000 [13:31<00:00,  2.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved probing results for Fold 2 to /media/manisha/DATA/dissertation_project/probing_readability_results/fold_1_probing_results.pkl\n",
      "\n",
      " Probing Fine-Tuned Model from Fold 3 \n",
      "\n",
      "Extracting embeddings from FKGL-tuned model and training probes for FKGL...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FKGL Probing: 100%|██████████| 2000/2000 [13:06<00:00,  2.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting embeddings from FRE-tuned model and training probes for FRE...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FRE Probing: 100%|██████████| 2000/2000 [13:09<00:00,  2.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved probing results for Fold 3 to /media/manisha/DATA/dissertation_project/probing_readability_results/fold_2_probing_results.pkl\n",
      "\n",
      " Probing Fine-Tuned Model from Fold 4 \n",
      "\n",
      "Extracting embeddings from FKGL-tuned model and training probes for FKGL...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FKGL Probing: 100%|██████████| 2000/2000 [13:04<00:00,  2.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting embeddings from FRE-tuned model and training probes for FRE...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FRE Probing: 100%|██████████| 2000/2000 [14:02<00:00,  2.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved probing results for Fold 4 to /media/manisha/DATA/dissertation_project/probing_readability_results/fold_3_probing_results.pkl\n",
      "\n",
      " Probing Fine-Tuned Model from Fold 5 \n",
      "\n",
      "Extracting embeddings from FKGL-tuned model and training probes for FKGL...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FKGL Probing: 100%|██████████| 2000/2000 [14:52<00:00,  2.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting embeddings from FRE-tuned model and training probes for FRE...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FRE Probing: 100%|██████████| 2000/2000 [14:59<00:00,  2.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved probing results for Fold 5 to /media/manisha/DATA/dissertation_project/probing_readability_results/fold_4_probing_results.pkl\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n Step 3: Probing Fine-Tuned Models \")\n",
    "\n",
    "probe_results_fkgl = {'mae': [], 'r2': []}\n",
    "probe_results_fre = {'mae': [], 'r2': []}\n",
    "\n",
    "N_SPLITS = 5\n",
    "kf = KFold(n_splits=N_SPLITS, shuffle=True, random_state=42)\n",
    "\n",
    "for fold_idx in range(N_SPLITS):\n",
    "    print(f\"\\n Probing Fine-Tuned Model from Fold {fold_idx + 1} \")\n",
    "\n",
    "    # loading fine-tuned FKGL and FRE models for this fold\n",
    "    ft_model_fkgl = DistilBertForSequenceClassification.from_pretrained(os.path.join(MODEL_DIR_FINE_TUNED, \"Fkgl\", f\"best_fold_{fold_idx}\"))\n",
    "    ft_model_fre = DistilBertForSequenceClassification.from_pretrained(os.path.join(MODEL_DIR_FINE_TUNED, \"Fre\", f\"best_fold_{fold_idx}\"))\n",
    "\n",
    "    base_fkgl_model = ft_model_fkgl.distilbert\n",
    "    base_fkgl_model.eval()\n",
    "    base_fre_model = ft_model_fre.distilbert\n",
    "    base_fre_model.eval()\n",
    "\n",
    "    # probing for FKGL on FKGL-tuned model \n",
    "    print(\"\\nExtracting embeddings from FKGL-tuned model and training probes for FKGL...\")\n",
    "    all_embs_fkgl_ft = [[] for _ in range(7)]\n",
    "    all_labels_fkgl_ft = []\n",
    "    for sent_idx in tqdm(range(len(probing_dataset)), desc=\"FKGL Probing\"):\n",
    "        sentence_embs = get_sentence_embedding(probing_dataset['text'][sent_idx], base_fkgl_model)\n",
    "        for layer_idx, emb in enumerate(sentence_embs):\n",
    "            all_embs_fkgl_ft[layer_idx].append(emb)\n",
    "        all_labels_fkgl_ft.append(probing_dataset['fkgl_score'][sent_idx])\n",
    "\n",
    "    concatenated_embs_fkgl_ft = [np.vstack(embs) for embs in all_embs_fkgl_ft]\n",
    "    y_fkgl_ft = np.array(all_labels_fkgl_ft)\n",
    "\n",
    "    for l_idx in range(7):\n",
    "        X = concatenated_embs_fkgl_ft[l_idx]\n",
    "        y = y_fkgl_ft\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        probe = LinearRegression(n_jobs=-1).fit(X_train, y_train)\n",
    "        y_pred = probe.predict(X_val)\n",
    "        probe_results_fkgl['mae'].append(mean_absolute_error(y_val, y_pred))\n",
    "        probe_results_fkgl['r2'].append(r2_score(y_val, y_pred))\n",
    "\n",
    "    # probing for FRE on FRE-tuned model \n",
    "    print(\"\\nExtracting embeddings from FRE-tuned model and training probes for FRE...\")\n",
    "    all_embs_fre_ft = [[] for _ in range(7)]\n",
    "    all_labels_fre_ft = []\n",
    "    for sent_idx in tqdm(range(len(probing_dataset)), desc=\"FRE Probing\"):\n",
    "        sentence_embs = get_sentence_embedding(probing_dataset['text'][sent_idx], base_fre_model)\n",
    "        for layer_idx, emb in enumerate(sentence_embs):\n",
    "            all_embs_fre_ft[layer_idx].append(emb)\n",
    "        all_labels_fre_ft.append(probing_dataset['fre_score'][sent_idx])\n",
    "\n",
    "    concatenated_embs_fre_ft = [np.vstack(embs) for embs in all_embs_fre_ft]\n",
    "    y_fre_ft = np.array(all_labels_fre_ft)\n",
    "\n",
    "    for l_idx in range(7):\n",
    "        X = concatenated_embs_fre_ft[l_idx]\n",
    "        y = y_fre_ft\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        probe = LinearRegression(n_jobs=-1).fit(X_train, y_train)\n",
    "        y_pred = probe.predict(X_val)\n",
    "        probe_results_fre['mae'].append(mean_absolute_error(y_val, y_pred))\n",
    "        probe_results_fre['r2'].append(r2_score(y_val, y_pred))\n",
    "\n",
    "    # saving probing results for this fold\n",
    "    current_fold_results = {\n",
    "        'fkgl': {'mae': [probe_results_fkgl['mae'][-1]], 'r2': [probe_results_fkgl['r2'][-1]]},\n",
    "        'fre': {'mae': [probe_results_fre['mae'][-1]], 'r2': [probe_results_fre['r2'][-1]]}\n",
    "    }\n",
    "    results_file_path = os.path.join(PROBE_RESULTS_DIR, f\"fold_{fold_idx}_probing_results.pkl\")\n",
    "    with open(results_file_path, 'wb') as f:\n",
    "        pickle.dump(current_fold_results, f)\n",
    "    print(f\"Saved probing results for Fold {fold_idx+1} to {results_file_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded results from the pickle file.\n",
      "{'fkgl': {'mae': [4.9219338785962465], 'r2': [0.5057721681406596]}, 'fre': {'mae': [35.00506759337448], 'r2': [0.45969566579847876]}}\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "file_path = os.path.join(\"probing_readability_results/fold_0_probing_results.pkl\") \n",
    "\n",
    "try:\n",
    "    with open(file_path, 'rb') as f:\n",
    "        loaded_results = pickle.load(f)\n",
    "\n",
    "    print(\"Successfully loaded results from the pickle file.\")\n",
    "    print(loaded_results)\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file '{file_path}' was not found.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while loading the pickle file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded results from the pickle file.\n",
      "{'fkgl': {'mae': [4.966901423163486], 'r2': [0.5166838429786087]}, 'fre': {'mae': [35.946583663366155], 'r2': [0.4462363840378545]}}\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "file_path = os.path.join(\"probing_readability_results/fold_1_probing_results.pkl\") \n",
    "\n",
    "try:\n",
    "    with open(file_path, 'rb') as f:\n",
    "        loaded_results = pickle.load(f)\n",
    "\n",
    "    print(\"Successfully loaded results from the pickle file.\")\n",
    "    print(loaded_results)\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file '{file_path}' was not found.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while loading the pickle file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded results from the pickle file.\n",
      "{'fkgl': {'mae': [4.986419403011531], 'r2': [0.4864674028827063]}, 'fre': {'mae': [35.78134271946314], 'r2': [0.4544334249441604]}}\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "file_path = os.path.join(\"probing_readability_results/fold_2_probing_results.pkl\") \n",
    "\n",
    "try:\n",
    "    with open(file_path, 'rb') as f:\n",
    "        loaded_results = pickle.load(f)\n",
    "\n",
    "    print(\"Successfully loaded results from the pickle file.\")\n",
    "    print(loaded_results)\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file '{file_path}' was not found.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while loading the pickle file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded results from the pickle file.\n",
      "{'fkgl': {'mae': [4.868628751805681], 'r2': [0.5061155317752646]}, 'fre': {'mae': [35.45475915371132], 'r2': [0.4523035083888456]}}\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "file_path = os.path.join(\"probing_readability_results/fold_3_probing_results.pkl\") \n",
    "\n",
    "try:\n",
    "    with open(file_path, 'rb') as f:\n",
    "        loaded_results = pickle.load(f)\n",
    "\n",
    "    print(\"Successfully loaded results from the pickle file.\")\n",
    "    print(loaded_results)\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file '{file_path}' was not found.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while loading the pickle file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded results from the pickle file.\n",
      "{'fkgl': {'mae': [4.851790768455783], 'r2': [0.5235318279700298]}, 'fre': {'mae': [35.04876806737689], 'r2': [0.4904187483331319]}}\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "file_path = os.path.join(\"probing_readability_results/fold_4_probing_results.pkl\") \n",
    "\n",
    "try:\n",
    "    with open(file_path, 'rb') as f:\n",
    "        loaded_results = pickle.load(f)\n",
    "\n",
    "    print(\"Successfully loaded results from the pickle file.\")\n",
    "    print(loaded_results)\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file '{file_path}' was not found.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while loading the pickle file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Step 4: Final Summary \n",
      "Final Probing Results on Fine-Tuned Models (Average across 5 folds)\n",
      "------------------------------------------------------------------\n",
      "FKGL Probe MAE: [np.float64(5.555387296536177), np.float64(4.700048560150932), np.float64(4.900910309580529), np.float64(4.7309735988843205), np.float64(4.685972081031418), np.float64(4.7612972925276065), np.float64(4.919134845006545)]\n",
      "FKGL Probe R2 Score: [np.float64(0.34255324253564673), np.float64(0.46941276145043087), np.float64(0.4834561656992068), np.float64(0.511117092371004), np.float64(0.5823825657010069), np.float64(0.5339884442720914), np.float64(0.5077141547494538)]\n",
      "\n",
      "FRE Probe MAE: [np.float64(39.39733959275429), np.float64(34.30090285071914), np.float64(34.624123772559145), np.float64(33.71717724920616), np.float64(34.083621528788335), np.float64(33.56014000628933), np.float64(35.447304239458404)]\n",
      "FRE Probe R2 Score: [np.float64(0.29676646393810946), np.float64(0.4238114001969482), np.float64(0.45071553410782983), np.float64(0.4816381535923965), np.float64(0.5347031756064137), np.float64(0.5220486911414441), np.float64(0.46061754630049423)]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n Step 4: Final Summary \")\n",
    "\n",
    "avg_probe_mae_fkgl_ft = [np.mean([probe_results_fkgl['mae'][fold_idx * 7 + l_idx] for fold_idx in range(5)]) for l_idx in range(7)]\n",
    "avg_probe_r2_fkgl_ft = [np.mean([probe_results_fkgl['r2'][fold_idx * 7 + l_idx] for fold_idx in range(5)]) for l_idx in range(7)]\n",
    "avg_probe_mae_fre_ft = [np.mean([probe_results_fre['mae'][fold_idx * 7 + l_idx] for fold_idx in range(5)]) for l_idx in range(7)]\n",
    "avg_probe_r2_fre_ft = [np.mean([probe_results_fre['r2'][fold_idx * 7 + l_idx] for fold_idx in range(5)]) for l_idx in range(7)]\n",
    "\n",
    "print(\"Final Probing Results on Fine-Tuned Models (Average across 5 folds)\")\n",
    "print(\"------------------------------------------------------------------\")\n",
    "print(\"FKGL Probe MAE:\", avg_probe_mae_fkgl_ft)\n",
    "print(\"FKGL Probe R2 Score:\", avg_probe_r2_fkgl_ft)\n",
    "print(\"\\nFRE Probe MAE:\", avg_probe_mae_fre_ft)\n",
    "print(\"FRE Probe R2 Score:\", avg_probe_r2_fre_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
