{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde505ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sharmajidotdev/manish/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Step 1: Data Preparation for Probing Fine Tuned Model \n",
      "Loading MRC Psycholinguistic Database...\n",
      "Total words in probing subset: 5000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import load_dataset, Dataset\n",
    "from tqdm.auto import tqdm\n",
    "import os\n",
    "import pickle\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from transformers import (\n",
    "    DistilBertModel,\n",
    "    DistilBertTokenizerFast,\n",
    "    DistilBertForSequenceClassification\n",
    ")\n",
    "\n",
    "print(\" Step 1: Data Preparation for Probing Fine Tuned Model \")\n",
    "\n",
    "try:\n",
    "    print(\"Loading MRC Psycholinguistic Database...\")\n",
    "    mrc_dataset = load_dataset(\"StephanAkkerman/MRC-psycholinguistic-database\")['train']\n",
    "\n",
    "    # extracting features \n",
    "    words = mrc_dataset['Word']\n",
    "    img = np.array(mrc_dataset['Imageability'], dtype=float)\n",
    "    conc = np.array(mrc_dataset['Concreteness'], dtype=float)\n",
    "    nsyl = np.array(mrc_dataset['Number of Syllables'], dtype=float)\n",
    "\n",
    "    valid = ~np.isnan(img) & ~np.isnan(conc) & ~np.isnan(nsyl)\n",
    "    words = [words[i] for i in range(len(words)) if valid[i]]\n",
    "    img = img[valid]\n",
    "    conc = conc[valid]\n",
    "    nsyl = nsyl[valid]\n",
    "    \n",
    "    # limiting  dataset to subset for faster processing\n",
    "    SUBSET_SIZE = 5000  \n",
    "    if len(words) > SUBSET_SIZE:\n",
    "        indices = np.arange(len(words))\n",
    "        np.random.seed(42)\n",
    "        np.random.shuffle(indices)\n",
    "        words = [words[i] for i in indices[:SUBSET_SIZE]]\n",
    "        img = img[indices[:SUBSET_SIZE]]\n",
    "        conc = conc[indices[:SUBSET_SIZE]]\n",
    "        nsyl = nsyl[indices[:SUBSET_SIZE]]\n",
    "\n",
    "    print(f\"Total words in probing subset: {len(words)}\")\n",
    "    \n",
    "    # creating a dataset object\n",
    "    probing_dataset = Dataset.from_dict({\n",
    "        'words': words,\n",
    "        'img': img.tolist(),\n",
    "        'conc': conc.tolist(),\n",
    "        'nsyl': nsyl.tolist()\n",
    "    })\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error preparing dataset: {e}\")\n",
    "    exit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9baf22ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Step 2: Probing Setup \n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n Step 2: Probing Setup \")\n",
    "model_name = 'distilbert-base-uncased'\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained(model_name)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# path to fine tuned models\n",
    "MODEL_DIR_FINE_TUNED = \"/home/sharmajidotdev/manish/models/readability\"\n",
    "PROBE_RESULTS_DIR = \"/home/sharmajidotdev/manish/probing_results_mrc\"\n",
    "os.makedirs(PROBE_RESULTS_DIR, exist_ok=True)\n",
    "\n",
    "def get_single_word_embedding_per_layer(word, model, tokenizer, device):\n",
    "    try:\n",
    "        base_model = model.distilbert\n",
    "        base_model.eval()\n",
    "\n",
    "        encoded = tokenizer(word, return_tensors='pt').to(device)\n",
    "        with torch.no_grad():\n",
    "            output = base_model(**encoded, output_hidden_states=True)\n",
    "        hidden_states = output.hidden_states\n",
    "        return [layer[0, 0, :].cpu().numpy() for layer in hidden_states]\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "def get_embeddings_for_set(word_list, label_list, desc):\n",
    "    all_embeddings = [[] for _ in range(7)]\n",
    "    all_labels = []\n",
    "    for i in tqdm(range(len(word_list)), desc=f\"{desc} Embeddings\"):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1066f79e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Step 3: Probing Fine Tuned Models ---\n",
      "\n",
      "--- Probing Fine-Tuned Model from Fold 1 ---\n",
      "\n",
      "Probing for Imageability (IMG) on FKGL-tuned model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IMG Probing: 100%|██████████| 5000/5000 [00:26<00:00, 185.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Probing for Concreteness (CONC) on FKGL-tuned model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CONC Probing: 100%|██████████| 5000/5000 [00:26<00:00, 192.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Probing for Number of Syllables (nSyl) on FRE-tuned model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NSYL Probing: 100%|██████████| 5000/5000 [00:26<00:00, 192.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved probing results for Fold 1 to //home/sharmajidotdev/manish/probing_results_mrc/fold_0_probing_results.pkl\n",
      "\n",
      "--- Probing Fine-Tuned Model from Fold 2 ---\n",
      "\n",
      "Probing for Imageability (IMG) on FKGL-tuned model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IMG Probing: 100%|██████████| 5000/5000 [00:26<00:00, 188.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Probing for Concreteness (CONC) on FKGL-tuned model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CONC Probing: 100%|██████████| 5000/5000 [00:25<00:00, 194.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Probing for Number of Syllables (nSyl) on FRE-tuned model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NSYL Probing: 100%|██████████| 5000/5000 [00:25<00:00, 195.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved probing results for Fold 2 to //home/sharmajidotdev/manish/probing_results_mrc/fold_1_probing_results.pkl\n",
      "\n",
      "--- Probing Fine-Tuned Model from Fold 3 ---\n",
      "\n",
      "Probing for Imageability (IMG) on FKGL-tuned model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IMG Probing: 100%|██████████| 5000/5000 [00:25<00:00, 199.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Probing for Concreteness (CONC) on FKGL-tuned model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CONC Probing: 100%|██████████| 5000/5000 [00:25<00:00, 197.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Probing for Number of Syllables (nSyl) on FRE-tuned model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NSYL Probing: 100%|██████████| 5000/5000 [00:25<00:00, 198.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved probing results for Fold 3 to //home/sharmajidotdev/manish/probing_results_mrc/fold_2_probing_results.pkl\n",
      "\n",
      "--- Probing Fine-Tuned Model from Fold 4 ---\n",
      "\n",
      "Probing for Imageability (IMG) on FKGL-tuned model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IMG Probing: 100%|██████████| 5000/5000 [00:25<00:00, 198.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Probing for Concreteness (CONC) on FKGL-tuned model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CONC Probing: 100%|██████████| 5000/5000 [00:26<00:00, 189.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Probing for Number of Syllables (nSyl) on FRE-tuned model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NSYL Probing: 100%|██████████| 5000/5000 [00:25<00:00, 199.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved probing results for Fold 4 to //home/sharmajidotdev/manish/probing_results_mrc/fold_3_probing_results.pkl\n",
      "\n",
      "--- Probing Fine-Tuned Model from Fold 5 ---\n",
      "\n",
      "Probing for Imageability (IMG) on FKGL-tuned model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IMG Probing: 100%|██████████| 5000/5000 [00:25<00:00, 198.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Probing for Concreteness (CONC) on FKGL-tuned model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CONC Probing: 100%|██████████| 5000/5000 [00:25<00:00, 198.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Probing for Number of Syllables (nSyl) on FRE-tuned model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NSYL Probing: 100%|██████████| 5000/5000 [00:25<00:00, 199.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved probing results for Fold 5 to //home/sharmajidotdev/manish/probing_results_mrc/fold_4_probing_results.pkl\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n Step 3: Probing Fine Tuned Models ---\")\n",
    "\n",
    "probe_results_img = {f\"layer_{i}\": {'mae': [], 'r2': []} for i in range(7)}\n",
    "probe_results_conc = {f\"layer_{i}\": {'mae': [], 'r2': []} for i in range(7)}\n",
    "probe_results_nsyl = {f\"layer_{i}\": {'mae': [], 'r2': []} for i in range(7)}\n",
    "\n",
    "N_SPLITS = 5\n",
    "kf = KFold(n_splits=N_SPLITS, shuffle=True, random_state=42)\n",
    "\n",
    "for fold_idx in range(N_SPLITS):\n",
    "    print(f\"\\n--- Probing Fine-Tuned Model from Fold {fold_idx + 1} ---\")\n",
    "\n",
    "   \n",
    "    ft_model_fkgl = DistilBertForSequenceClassification.from_pretrained(os.path.join(MODEL_DIR_FINE_TUNED, \"Fkgl\", f\"best_fold_{fold_idx}\"))\n",
    "    ft_model_fkgl.to(device)\n",
    "    ft_model_fre = DistilBertForSequenceClassification.from_pretrained(os.path.join(MODEL_DIR_FINE_TUNED, \"Fre\", f\"best_fold_{fold_idx}\"))\n",
    "    ft_model_fre.to(device)\n",
    "    \n",
    "    # probing for imageability\n",
    "    print(\"\\nProbing for Imageability (IMG) on FKGL-tuned model...\")\n",
    "    all_embs_img = [[] for _ in range(7)]\n",
    "    all_labels_img = []\n",
    "    for i in tqdm(range(len(probing_dataset['words'])), desc=\"IMG Probing\"):\n",
    "        embs = get_single_word_embedding_per_layer(probing_dataset['words'][i], ft_model_fkgl, tokenizer, device)\n",
    "        if embs:\n",
    "            for l_idx, emb in enumerate(embs):\n",
    "                all_embs_img[l_idx].append(emb)\n",
    "            all_labels_img.append(probing_dataset['img'][i])\n",
    "\n",
    "    concatenated_embs_img = [np.vstack(embs) for embs in all_embs_img]\n",
    "    y_img = np.array(all_labels_img)\n",
    "    for l_idx in range(7):\n",
    "        X_train, X_val, y_train, y_val = train_test_split(concatenated_embs_img[l_idx], y_img, test_size=0.2, random_state=42)\n",
    "        probe = LinearRegression(n_jobs=-1).fit(X_train, y_train)\n",
    "        preds = probe.predict(X_val)\n",
    "        probe_results_img[f\"layer_{l_idx}\"]['mae'].append(mean_absolute_error(y_val, preds))\n",
    "        probe_results_img[f\"layer_{l_idx}\"]['r2'].append(r2_score(y_val, preds))\n",
    "\n",
    "    # probing for concreteness\n",
    "    print(\"\\nProbing for Concreteness (CONC) on FKGL-tuned model...\")\n",
    "    all_embs_conc = [[] for _ in range(7)]\n",
    "    all_labels_conc = []\n",
    "    for i in tqdm(range(len(probing_dataset['words'])), desc=\"CONC Probing\"):\n",
    "        embs = get_single_word_embedding_per_layer(probing_dataset['words'][i], ft_model_fkgl, tokenizer, device)\n",
    "        if embs:\n",
    "            for l_idx, emb in enumerate(embs):\n",
    "                all_embs_conc[l_idx].append(emb)\n",
    "            all_labels_conc.append(probing_dataset['conc'][i])\n",
    "\n",
    "    concatenated_embs_conc = [np.vstack(embs) for embs in all_embs_conc]\n",
    "    y_conc = np.array(all_labels_conc)\n",
    "    for l_idx in range(7):\n",
    "        X_train, X_val, y_train, y_val = train_test_split(concatenated_embs_conc[l_idx], y_conc, test_size=0.2, random_state=42)\n",
    "        probe = LinearRegression(n_jobs=-1).fit(X_train, y_train)\n",
    "        preds = probe.predict(X_val)\n",
    "        probe_results_conc[f\"layer_{l_idx}\"]['mae'].append(mean_absolute_error(y_val, preds))\n",
    "        probe_results_conc[f\"layer_{l_idx}\"]['r2'].append(r2_score(y_val, preds))\n",
    "\n",
    "    # extra step\n",
    "    # probing for number of syllables\n",
    "    print(\"\\nProbing for Number of Syllables (nSyl) on FRE-tuned model...\")\n",
    "    all_embs_nsyl = [[] for _ in range(7)]\n",
    "    all_labels_nsyl = []\n",
    "    for i in tqdm(range(len(probing_dataset['words'])), desc=\"NSYL Probing\"):\n",
    "        embs = get_single_word_embedding_per_layer(probing_dataset['words'][i], ft_model_fre, tokenizer, device)\n",
    "        if embs:\n",
    "            for l_idx, emb in enumerate(embs):\n",
    "                all_embs_nsyl[l_idx].append(emb)\n",
    "            all_labels_nsyl.append(probing_dataset['nsyl'][i])\n",
    "\n",
    "    concatenated_embs_nsyl = [np.vstack(embs) for embs in all_embs_nsyl]\n",
    "    y_nsyl = np.array(all_labels_nsyl)\n",
    "    for l_idx in range(7):\n",
    "        X_train, X_val, y_train, y_val = train_test_split(concatenated_embs_nsyl[l_idx], y_nsyl, test_size=0.2, random_state=42)\n",
    "        probe = LinearRegression(n_jobs=-1).fit(X_train, y_train)\n",
    "        preds = probe.predict(X_val)\n",
    "        probe_results_nsyl[f\"layer_{l_idx}\"]['mae'].append(mean_absolute_error(y_val, preds))\n",
    "        probe_results_nsyl[f\"layer_{l_idx}\"]['r2'].append(r2_score(y_val, preds))\n",
    "        \n",
    "    # saving probing results for this fold\n",
    "    current_fold_results = {\n",
    "        'img': probe_results_img,\n",
    "        'conc': probe_results_conc,\n",
    "        'nsyl': probe_results_nsyl\n",
    "    }\n",
    "    results_file_path = os.path.join(PROBE_RESULTS_DIR, f\"fold_{fold_idx}_probing_results.pkl\")\n",
    "    with open(results_file_path, 'wb') as f:\n",
    "        pickle.dump(current_fold_results, f)\n",
    "    print(f\"Saved probing results for Fold {fold_idx+1} to {results_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd0394ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Successfully loaded results from pickle file.\n",
      "{'img': {'layer_0': {'mae': [57.68554726028442], 'r2': [-0.0018860426594220492]}, 'layer_1': {'mae': [74.18200390625], 'r2': [0.1552451113455685]}, 'layer_2': {'mae': [69.49881713867188], 'r2': [0.2351678415354158]}, 'layer_3': {'mae': [63.87974560546875], 'r2': [0.31318013776715203]}, 'layer_4': {'mae': [63.10501547241211], 'r2': [0.320938944600652]}, 'layer_5': {'mae': [65.35499395751953], 'r2': [0.28954012101569915]}, 'layer_6': {'mae': [65.99402333068848], 'r2': [0.2674454719934056]}}, 'conc': {'layer_0': {'mae': [49.7856877746582], 'r2': [-0.0016943585725441856]}, 'layer_1': {'mae': [68.77723388671875], 'r2': [0.10103681510127627]}, 'layer_2': {'mae': [64.50417651367188], 'r2': [0.17565636306282628]}, 'layer_3': {'mae': [59.574143432617184], 'r2': [0.26162629065377074]}, 'layer_4': {'mae': [58.585062652587894], 'r2': [0.2750231572140036]}, 'layer_5': {'mae': [60.961970581054686], 'r2': [0.22989584855368095]}, 'layer_6': {'mae': [61.165807678222656], 'r2': [0.23747132391498882]}}, 'nsyl': {'layer_0': {'mae': [1.320765971660614], 'r2': [-0.00023950584733078983]}, 'layer_1': {'mae': [0.8946083984375], 'r2': [0.425337447453804]}, 'layer_2': {'mae': [0.8418868675231933], 'r2': [0.5000332768528498]}, 'layer_3': {'mae': [0.8120684013366699], 'r2': [0.5091202842960124]}, 'layer_4': {'mae': [0.7408508348464966], 'r2': [0.5905470972251982]}, 'layer_5': {'mae': [0.7394329929351806], 'r2': [0.5826672134516024]}, 'layer_6': {'mae': [0.7748952045440674], 'r2': [0.5393102607292405]}}}\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "\n",
    "file_path = os.path.join(\"probing_results_mrc/fold_0_probing_results.pkl\") \n",
    "\n",
    "try:\n",
    "    with open(file_path, 'rb') as f:\n",
    "        loaded_results = pickle.load(f)\n",
    "\n",
    "    # printing contents of dictionary\n",
    "    print(\"\\n Successfully loaded results from pickle file.\")\n",
    "    print(loaded_results)\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file '{file_path}' was not found.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while loading the pickle file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1082887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Successfully loaded results from pickle file.\n",
      "{'img': {'layer_0': {'mae': [57.68554726028442, 57.68547592544556], 'r2': [-0.0018860426594220492, -0.0018861026978154172]}, 'layer_1': {'mae': [74.18200390625, 74.2060703125], 'r2': [0.1552451113455685, 0.1549061114151037]}, 'layer_2': {'mae': [69.49881713867188, 69.75066194152832], 'r2': [0.2351678415354158, 0.2401214027187688]}, 'layer_3': {'mae': [63.87974560546875, 63.90389703369141], 'r2': [0.31318013776715203, 0.32284884427422966]}, 'layer_4': {'mae': [63.10501547241211, 62.762173881530764], 'r2': [0.320938944600652, 0.3487336124458039]}, 'layer_5': {'mae': [65.35499395751953, 67.21907653808594], 'r2': [0.28954012101569915, 0.26327397881747094]}, 'layer_6': {'mae': [65.99402333068848, 67.22021569824219], 'r2': [0.2674454719934056, 0.2638259858205416]}}, 'conc': {'layer_0': {'mae': [49.7856877746582, 49.785639873504635], 'r2': [-0.0016943585725441856, -0.0016943994983706911]}, 'layer_1': {'mae': [68.77723388671875, 68.49631005859375], 'r2': [0.10103681510127627, 0.10167147247723574]}, 'layer_2': {'mae': [64.50417651367188, 65.05288647460938], 'r2': [0.17565636306282628, 0.1735939688017899]}, 'layer_3': {'mae': [59.574143432617184, 60.00426528930664], 'r2': [0.26162629065377074, 0.26952348474178145]}, 'layer_4': {'mae': [58.585062652587894, 58.40730596923828], 'r2': [0.2750231572140036, 0.29890182553290834]}, 'layer_5': {'mae': [60.961970581054686, 61.450428520202635], 'r2': [0.22989584855368095, 0.2167035678797763]}, 'layer_6': {'mae': [61.165807678222656, 62.415059173583984], 'r2': [0.23747132391498882, 0.2329563000028626]}}, 'nsyl': {'layer_0': {'mae': [1.320765971660614, 1.320766052722931], 'r2': [-0.00023950584733078983, -0.00023948154938069344]}, 'layer_1': {'mae': [0.8946083984375, 0.8935096282958984], 'r2': [0.425337447453804, 0.41553581736749834]}, 'layer_2': {'mae': [0.8418868675231933, 0.850892562866211], 'r2': [0.5000332768528498, 0.4892434748147333]}, 'layer_3': {'mae': [0.8120684013366699, 0.7974175441265107], 'r2': [0.5091202842960124, 0.5228363232120258]}, 'layer_4': {'mae': [0.7408508348464966, 0.7525240421295166], 'r2': [0.5905470972251982, 0.5826655008343689]}, 'layer_5': {'mae': [0.7394329929351806, 0.7514079837799073], 'r2': [0.5826672134516024, 0.5781653102359996]}, 'layer_6': {'mae': [0.7748952045440674, 0.8013697943687439], 'r2': [0.5393102607292405, 0.5280346269268947]}}}\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "\n",
    "file_path = os.path.join(\"probing_results_mrc/fold_1_probing_results.pkl\") \n",
    "\n",
    "try:\n",
    "    with open(file_path, 'rb') as f:\n",
    "        loaded_results = pickle.load(f)\n",
    "\n",
    "    # printing contents of dictionary\n",
    "    print(\"\\n Successfully loaded results from pickle file.\")\n",
    "    print(loaded_results)\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file '{file_path}' was not found.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while loading the pickle file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f2e72b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Successfully loaded results from pickle file.\n",
      "{'img': {'layer_0': {'mae': [57.68554726028442, 57.68547592544556, 57.6855634727478], 'r2': [-0.0018860426594220492, -0.0018861026978154172, -0.0018860290144655512]}, 'layer_1': {'mae': [74.18200390625, 74.2060703125, 74.223466796875], 'r2': [0.1552451113455685, 0.1549061114151037, 0.15610773788642207]}, 'layer_2': {'mae': [69.49881713867188, 69.75066194152832, 69.33259375], 'r2': [0.2351678415354158, 0.2401214027187688, 0.2337276223191972]}, 'layer_3': {'mae': [63.87974560546875, 63.90389703369141, 63.97260827636719], 'r2': [0.31318013776715203, 0.32284884427422966, 0.32595952717555754]}, 'layer_4': {'mae': [63.10501547241211, 62.762173881530764, 63.309162658691406], 'r2': [0.320938944600652, 0.3487336124458039, 0.3487606959404186]}, 'layer_5': {'mae': [65.35499395751953, 67.21907653808594, 65.1996748046875], 'r2': [0.28954012101569915, 0.26327397881747094, 0.31024247696870866]}, 'layer_6': {'mae': [65.99402333068848, 67.22021569824219, 67.23629779052735], 'r2': [0.2674454719934056, 0.2638259858205416, 0.2616315944586566]}}, 'conc': {'layer_0': {'mae': [49.7856877746582, 49.785639873504635, 49.78573237228394], 'r2': [-0.0016943585725441856, -0.0016943994983706911, -0.0016943204696335812]}, 'layer_1': {'mae': [68.77723388671875, 68.49631005859375, 68.78022509765626], 'r2': [0.10103681510127627, 0.10167147247723574, 0.10413345282949349]}, 'layer_2': {'mae': [64.50417651367188, 65.05288647460938, 64.444408203125], 'r2': [0.17565636306282628, 0.1735939688017899, 0.17126464562922739]}, 'layer_3': {'mae': [59.574143432617184, 60.00426528930664, 59.625030639648436], 'r2': [0.26162629065377074, 0.26952348474178145, 0.268254309932492]}, 'layer_4': {'mae': [58.585062652587894, 58.40730596923828, 59.1774870300293], 'r2': [0.2750231572140036, 0.29890182553290834, 0.2923635698294451]}, 'layer_5': {'mae': [60.961970581054686, 61.450428520202635, 59.205546630859374], 'r2': [0.22989584855368095, 0.2167035678797763, 0.28315306178446575]}, 'layer_6': {'mae': [61.165807678222656, 62.415059173583984, 62.16228555297852], 'r2': [0.23747132391498882, 0.2329563000028626, 0.2462751677715107]}}, 'nsyl': {'layer_0': {'mae': [1.320765971660614, 1.320766052722931, 1.3207660284042357], 'r2': [-0.00023950584733078983, -0.00023948154938069344, -0.00023948883863611492]}, 'layer_1': {'mae': [0.8946083984375, 0.8935096282958984, 0.8922372703552246], 'r2': [0.425337447453804, 0.41553581736749834, 0.4170680309339799]}, 'layer_2': {'mae': [0.8418868675231933, 0.850892562866211, 0.850781566619873], 'r2': [0.5000332768528498, 0.4892434748147333, 0.4886393832366518]}, 'layer_3': {'mae': [0.8120684013366699, 0.7974175441265107, 0.8005824649333954], 'r2': [0.5091202842960124, 0.5228363232120258, 0.517983955696123]}, 'layer_4': {'mae': [0.7408508348464966, 0.7525240421295166, 0.759669870376587], 'r2': [0.5905470972251982, 0.5826655008343689, 0.5794606609907199]}, 'layer_5': {'mae': [0.7394329929351806, 0.7514079837799073, 0.7574739360809326], 'r2': [0.5826672134516024, 0.5781653102359996, 0.579086091316664]}, 'layer_6': {'mae': [0.7748952045440674, 0.8013697943687439, 0.8079673318862916], 'r2': [0.5393102607292405, 0.5280346269268947, 0.5268069541196343]}}}\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "\n",
    "file_path = os.path.join(\"probing_results_mrc/fold_2_probing_results.pkl\") \n",
    "\n",
    "try:\n",
    "    with open(file_path, 'rb') as f:\n",
    "        loaded_results = pickle.load(f)\n",
    "\n",
    "    # printing contents of dictionary\n",
    "    print(\"\\n Successfully loaded results from pickle file.\")\n",
    "    print(loaded_results)\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file '{file_path}' was not found.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while loading the pickle file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0ac8d79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Successfully loaded results from pickle file.\n",
      "{'img': {'layer_0': {'mae': [57.68554726028442, 57.68547592544556, 57.6855634727478, 57.68550997161865], 'r2': [-0.0018860426594220492, -0.0018861026978154172, -0.0018860290144655512, -0.0018860740430082235]}, 'layer_1': {'mae': [74.18200390625, 74.2060703125, 74.223466796875, 74.446306640625], 'r2': [0.1552451113455685, 0.1549061114151037, 0.15610773788642207, 0.15532090364375462]}, 'layer_2': {'mae': [69.49881713867188, 69.75066194152832, 69.33259375, 69.43986096191406], 'r2': [0.2351678415354158, 0.2401214027187688, 0.2337276223191972, 0.2345976574478842]}, 'layer_3': {'mae': [63.87974560546875, 63.90389703369141, 63.97260827636719, 64.3610574951172], 'r2': [0.31318013776715203, 0.32284884427422966, 0.32595952717555754, 0.3183182963407478]}, 'layer_4': {'mae': [63.10501547241211, 62.762173881530764, 63.309162658691406, 63.267041595458984], 'r2': [0.320938944600652, 0.3487336124458039, 0.3487606959404186, 0.34793138689444436]}, 'layer_5': {'mae': [65.35499395751953, 67.21907653808594, 65.1996748046875, 66.19861401367187], 'r2': [0.28954012101569915, 0.26327397881747094, 0.31024247696870866, 0.3008704151722431]}, 'layer_6': {'mae': [65.99402333068848, 67.22021569824219, 67.23629779052735, 67.6356651611328], 'r2': [0.2674454719934056, 0.2638259858205416, 0.2616315944586566, 0.26064069654355526]}}, 'conc': {'layer_0': {'mae': [49.7856877746582, 49.785639873504635, 49.78573237228394, 49.78567786407471], 'r2': [-0.0016943585725441856, -0.0016943994983706911, -0.0016943204696335812, -0.0016943670399156563]}, 'layer_1': {'mae': [68.77723388671875, 68.49631005859375, 68.78022509765626, 68.8558173828125], 'r2': [0.10103681510127627, 0.10167147247723574, 0.10413345282949349, 0.10415226011360801]}, 'layer_2': {'mae': [64.50417651367188, 65.05288647460938, 64.444408203125, 64.55775646972656], 'r2': [0.17565636306282628, 0.1735939688017899, 0.17126464562922739, 0.17081315833879418]}, 'layer_3': {'mae': [59.574143432617184, 60.00426528930664, 59.625030639648436, 59.70596028137207], 'r2': [0.26162629065377074, 0.26952348474178145, 0.268254309932492, 0.2636718516018267]}, 'layer_4': {'mae': [58.585062652587894, 58.40730596923828, 59.1774870300293, 59.015711715698245], 'r2': [0.2750231572140036, 0.29890182553290834, 0.2923635698294451, 0.2873060592668468]}, 'layer_5': {'mae': [60.961970581054686, 61.450428520202635, 59.205546630859374, 59.909232177734374], 'r2': [0.22989584855368095, 0.2167035678797763, 0.28315306178446575, 0.27277955096322726]}, 'layer_6': {'mae': [61.165807678222656, 62.415059173583984, 62.16228555297852, 62.200757354736325], 'r2': [0.23747132391498882, 0.2329563000028626, 0.2462751677715107, 0.2433340393279938]}}, 'nsyl': {'layer_0': {'mae': [1.320765971660614, 1.320766052722931, 1.3207660284042357, 1.3207660284042357], 'r2': [-0.00023950584733078983, -0.00023948154938069344, -0.00023948883863611492, -0.00023948883863611492]}, 'layer_1': {'mae': [0.8946083984375, 0.8935096282958984, 0.8922372703552246, 0.8937645111083984], 'r2': [0.425337447453804, 0.41553581736749834, 0.4170680309339799, 0.41573327367839497]}, 'layer_2': {'mae': [0.8418868675231933, 0.850892562866211, 0.850781566619873, 0.8515443534851074], 'r2': [0.5000332768528498, 0.4892434748147333, 0.4886393832366518, 0.48678175378661803]}, 'layer_3': {'mae': [0.8120684013366699, 0.7974175441265107, 0.8005824649333954, 0.7959036498069764], 'r2': [0.5091202842960124, 0.5228363232120258, 0.517983955696123, 0.5221346493473787]}, 'layer_4': {'mae': [0.7408508348464966, 0.7525240421295166, 0.759669870376587, 0.753285460472107], 'r2': [0.5905470972251982, 0.5826655008343689, 0.5794606609907199, 0.5844079245090845]}, 'layer_5': {'mae': [0.7394329929351806, 0.7514079837799073, 0.7574739360809326, 0.7626233673095704], 'r2': [0.5826672134516024, 0.5781653102359996, 0.579086091316664, 0.5721933569393329]}, 'layer_6': {'mae': [0.7748952045440674, 0.8013697943687439, 0.8079673318862916, 0.8068390860557556], 'r2': [0.5393102607292405, 0.5280346269268947, 0.5268069541196343, 0.525641293985793]}}}\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "\n",
    "file_path = os.path.join(\"probing_results_mrc/fold_3_probing_results.pkl\") \n",
    "\n",
    "try:\n",
    "    with open(file_path, 'rb') as f:\n",
    "        loaded_results = pickle.load(f)\n",
    "\n",
    "    # printing contents of dictionary\n",
    "    print(\"\\n Successfully loaded results from pickle file.\")\n",
    "    print(loaded_results)\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file '{file_path}' was not found.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while loading the pickle file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b168b9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Successfully loaded results from pickle file.\n",
      "{'img': {'layer_0': {'mae': [57.68554726028442, 57.68547592544556, 57.6855634727478, 57.68550997161865, 57.685471061706544], 'r2': [-0.0018860426594220492, -0.0018861026978154172, -0.0018860290144655512, -0.0018860740430082235, -0.001886106791376907]}, 'layer_1': {'mae': [74.18200390625, 74.2060703125, 74.223466796875, 74.446306640625, 74.4329287109375], 'r2': [0.1552451113455685, 0.1549061114151037, 0.15610773788642207, 0.15532090364375462, 0.15597929881050865]}, 'layer_2': {'mae': [69.49881713867188, 69.75066194152832, 69.33259375, 69.43986096191406, 69.30650720214844], 'r2': [0.2351678415354158, 0.2401214027187688, 0.2337276223191972, 0.2345976574478842, 0.23479133568307764]}, 'layer_3': {'mae': [63.87974560546875, 63.90389703369141, 63.97260827636719, 64.3610574951172, 64.33193334960937], 'r2': [0.31318013776715203, 0.32284884427422966, 0.32595952717555754, 0.3183182963407478, 0.32081942250822604]}, 'layer_4': {'mae': [63.10501547241211, 62.762173881530764, 63.309162658691406, 63.267041595458984, 62.61264498138428], 'r2': [0.320938944600652, 0.3487336124458039, 0.3487606959404186, 0.34793138689444436, 0.3544073762148692]}, 'layer_5': {'mae': [65.35499395751953, 67.21907653808594, 65.1996748046875, 66.19861401367187, 65.02443310546874], 'r2': [0.28954012101569915, 0.26327397881747094, 0.31024247696870866, 0.3008704151722431, 0.31999975734587593]}, 'layer_6': {'mae': [65.99402333068848, 67.22021569824219, 67.23629779052735, 67.6356651611328, 67.54968908691406], 'r2': [0.2674454719934056, 0.2638259858205416, 0.2616315944586566, 0.26064069654355526, 0.2650518654961912]}}, 'conc': {'layer_0': {'mae': [49.7856877746582, 49.785639873504635, 49.78573237228394, 49.78567786407471, 49.78563491821289], 'r2': [-0.0016943585725441856, -0.0016943994983706911, -0.0016943204696335812, -0.0016943670399156563, -0.0016944037321047212]}, 'layer_1': {'mae': [68.77723388671875, 68.49631005859375, 68.78022509765626, 68.8558173828125, 68.90300244140624], 'r2': [0.10103681510127627, 0.10167147247723574, 0.10413345282949349, 0.10415226011360801, 0.10268985774119022]}, 'layer_2': {'mae': [64.50417651367188, 65.05288647460938, 64.444408203125, 64.55775646972656, 64.33287158203125], 'r2': [0.17565636306282628, 0.1735939688017899, 0.17126464562922739, 0.17081315833879418, 0.17157053514326348]}, 'layer_3': {'mae': [59.574143432617184, 60.00426528930664, 59.625030639648436, 59.70596028137207, 59.866927505493166], 'r2': [0.26162629065377074, 0.26952348474178145, 0.268254309932492, 0.2636718516018267, 0.26366543039961987]}, 'layer_4': {'mae': [58.585062652587894, 58.40730596923828, 59.1774870300293, 59.015711715698245, 58.52984378051758], 'r2': [0.2750231572140036, 0.29890182553290834, 0.2923635698294451, 0.2873060592668468, 0.2980767899713995]}, 'layer_5': {'mae': [60.961970581054686, 61.450428520202635, 59.205546630859374, 59.909232177734374, 59.08778491210938], 'r2': [0.22989584855368095, 0.2167035678797763, 0.28315306178446575, 0.27277955096322726, 0.28990843420239576]}, 'layer_6': {'mae': [61.165807678222656, 62.415059173583984, 62.16228555297852, 62.200757354736325, 63.0348369140625], 'r2': [0.23747132391498882, 0.2329563000028626, 0.2462751677715107, 0.2433340393279938, 0.2409172291472087]}}, 'nsyl': {'layer_0': {'mae': [1.320765971660614, 1.320766052722931, 1.3207660284042357, 1.3207660284042357, 1.3207660040855407], 'r2': [-0.00023950584733078983, -0.00023948154938069344, -0.00023948883863611492, -0.00023948883863611492, -0.0002394961280030028]}, 'layer_1': {'mae': [0.8946083984375, 0.8935096282958984, 0.8922372703552246, 0.8937645111083984, 0.8944902114868164], 'r2': [0.425337447453804, 0.41553581736749834, 0.4170680309339799, 0.41573327367839497, 0.41221447196172245]}, 'layer_2': {'mae': [0.8418868675231933, 0.850892562866211, 0.850781566619873, 0.8515443534851074, 0.8504243354797363], 'r2': [0.5000332768528498, 0.4892434748147333, 0.4886393832366518, 0.48678175378661803, 0.48860327248223734]}, 'layer_3': {'mae': [0.8120684013366699, 0.7974175441265107, 0.8005824649333954, 0.7959036498069764, 0.7934606447219849], 'r2': [0.5091202842960124, 0.5228363232120258, 0.517983955696123, 0.5221346493473787, 0.5275098294412464]}, 'layer_4': {'mae': [0.7408508348464966, 0.7525240421295166, 0.759669870376587, 0.753285460472107, 0.7532868871688843], 'r2': [0.5905470972251982, 0.5826655008343689, 0.5794606609907199, 0.5844079245090845, 0.5825889903768591]}, 'layer_5': {'mae': [0.7394329929351806, 0.7514079837799073, 0.7574739360809326, 0.7626233673095704, 0.7607603225708007], 'r2': [0.5826672134516024, 0.5781653102359996, 0.579086091316664, 0.5721933569393329, 0.5782024719926673]}, 'layer_6': {'mae': [0.7748952045440674, 0.8013697943687439, 0.8079673318862916, 0.8068390860557556, 0.8061835408210755], 'r2': [0.5393102607292405, 0.5280346269268947, 0.5268069541196343, 0.525641293985793, 0.521383869508126]}}}\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "\n",
    "file_path = os.path.join(\"probing_results_mrc/fold_4_probing_results.pkl\") \n",
    "\n",
    "try:\n",
    "    with open(file_path, 'rb') as f:\n",
    "        loaded_results = pickle.load(f)\n",
    "\n",
    "    # printing contents of dictionary\n",
    "    print(\"\\n Successfully loaded results from pickle file.\")\n",
    "    print(loaded_results)\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file '{file_path}' was not found.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while loading the pickle file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3123f63a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Step 4: Final Summary \n",
      "Final Probing Results on Fine-Tuned Models (Average across 5 folds)\n",
      "------------------------------------------------------------------\n",
      "Imageability Probe MAE: [np.float64(57.68551353836059), np.float64(74.2981552734375), np.float64(69.46568819885255), np.float64(64.08984835205078), np.float64(63.011207717895516), np.float64(65.79935848388672), np.float64(67.12717821350097)]\n",
      "Imageability Probe R2 Score: [np.float64(-0.0018860710412176296), np.float64(0.15551183262027152), np.float64(0.23568117194086874), np.float64(0.3202252456131826), np.float64(0.3441544032192376), np.float64(0.29678534986399957), np.float64(0.2637191228624701)]\n",
      "\n",
      "Concreteness Probe MAE: [np.float64(49.78567456054687), np.float64(68.76251777343751), np.float64(64.57841984863282), np.float64(59.7552654296875), np.float64(58.74308222961427), np.float64(60.122992564392085), np.float64(62.1957493347168)]\n",
      "Concreteness Probe R2 Score: [np.float64(-0.001694369862513767), np.float64(0.10273677165256075), np.float64(0.17257973419518025), np.float64(0.2653482734658982), np.float64(0.2903342803629207), np.float64(0.25848809267670925), np.float64(0.24019081203291295)]\n",
      "\n",
      "Number of Syllables Probe MAE: [np.float64(1.3207660170555113), np.float64(0.8937220039367675), np.float64(0.8491059371948243), np.float64(0.7998865409851074), np.float64(0.7519234189987183), np.float64(0.7543397205352783), np.float64(0.7994509915351867)]\n",
      "Number of Syllables Probe R2 Score: [np.float64(-0.00023949224039734318), np.float64(0.41717780827907996), np.float64(0.49066023223461813), np.float64(0.5199170083985573), np.float64(0.5839340347872461), np.float64(0.5780628887872533), np.float64(0.5282354010539377)]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n Step 4: Final Summary \")\n",
    "avg_probe_mae_img = [np.mean(probe_results_img[f\"layer_{i}\"]['mae']) for i in range(7)]\n",
    "avg_probe_r2_img = [np.mean(probe_results_img[f\"layer_{i}\"]['r2']) for i in range(7)]\n",
    "avg_probe_mae_conc = [np.mean(probe_results_conc[f\"layer_{i}\"]['mae']) for i in range(7)]\n",
    "avg_probe_r2_conc = [np.mean(probe_results_conc[f\"layer_{i}\"]['r2']) for i in range(7)]\n",
    "avg_probe_mae_nsyl = [np.mean(probe_results_nsyl[f\"layer_{i}\"]['mae']) for i in range(7)]\n",
    "avg_probe_r2_nsyl = [np.mean(probe_results_nsyl[f\"layer_{i}\"]['r2']) for i in range(7)]\n",
    "\n",
    "print(\"Final Probing Results on Fine-Tuned Models (Average across 5 folds)\")\n",
    "print(\"------------------------------------------------------------------\")\n",
    "print(\"Imageability Probe MAE:\", avg_probe_mae_img)\n",
    "print(\"Imageability Probe R2 Score:\", avg_probe_r2_img)\n",
    "print(\"\\nConcreteness Probe MAE:\", avg_probe_mae_conc)\n",
    "print(\"Concreteness Probe R2 Score:\", avg_probe_r2_conc)\n",
    "print(\"\\nNumber of Syllables Probe MAE:\", avg_probe_mae_nsyl)\n",
    "print(\"Number of Syllables Probe R2 Score:\", avg_probe_r2_nsyl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92166ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
